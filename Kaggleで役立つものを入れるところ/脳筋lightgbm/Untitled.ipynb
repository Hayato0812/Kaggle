{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "    test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "is_train         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('float64'),\n",
       " dtype('int64'),\n",
       " dtype('int64'),\n",
       " dtype('O'),\n",
       " dtype('float64'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('int64')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_df.dtypes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int64'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(train_df.dtypes.values)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int64'), dtype('int64'), dtype('int64'), dtype('O'),\n",
       "       dtype('O'), dtype('float64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('O'), dtype('float64'), dtype('O'), dtype('O')], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dd25d55b4e9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    " list(train_df.dtypes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9e3194819cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     if  dtype ==\"dtype('O')\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "for dtype in list(train_df.dtypes.values()):\n",
    "    print( dtype)\n",
    "#     if  dtype ==\"dtype('O')\":\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       aaa\n",
       "1       C85\n",
       "2       aaa\n",
       "3      C123\n",
       "4       aaa\n",
       "       ... \n",
       "886     aaa\n",
       "887     B42\n",
       "888     aaa\n",
       "889    C148\n",
       "890     aaa\n",
       "Name: Cabin, Length: 891, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Cabin\"].fillna(\"aaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "is_train         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df[\"Cabin\"].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 15:29:56,289] Finished trial#0 resulted in value: 0.8024417801770134. Current best value is 0.8024417801770134 with parameters: {'lambda_l1': 0.01007534045122637, 'lambda_l2': 2.8537356571466826e-07, 'num_leaves': 180, 'feature_fraction': 0.7807180524166191, 'bagging_fraction': 0.4225197119630312, 'bagging_freq': 1, 'min_child_samples': 69}.\n",
      "[I 2019-12-11 15:29:57,580] Finished trial#1 resulted in value: 0.8215240725629276. Current best value is 0.8215240725629276 with parameters: {'lambda_l1': 0.1871875138806655, 'lambda_l2': 7.694254834511715e-05, 'num_leaves': 239, 'feature_fraction': 0.9516662769431276, 'bagging_fraction': 0.949755419696052, 'bagging_freq': 5, 'min_child_samples': 38}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_score→0.8215240725629276\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "    test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocessing(train_df,test_df, id_name):\n",
    "    train_df[\"is_train\"] = 1\n",
    "    test_df[\"is_train\"] = 0\n",
    "    target = set(list(train_df.columns)) ^ set(list(test_df.columns))\n",
    "    target_df = train_df[target]\n",
    "    train_df = train_df.drop(target,axis=1)\n",
    "    all_data = pd.concat([train_df,test_df])\n",
    "    # objectカラムの取得\n",
    "    change_columns =[]\n",
    "    for index_name, dtype in zip(list(train_df.dtypes.index),list(train_df.dtypes.values)):\n",
    "        if  str(dtype) =='object':\n",
    "            change_columns.append(index_name)\n",
    "    train_df[change_columns] = list(train_df[change_columns].fillna(\"欠損\"))\n",
    "    target_column = train_df[change_columns]\n",
    "    for column in change_columns:\n",
    "        le = LabelEncoder()\n",
    "        select_df = all_data[column].astype(str)\n",
    "        le.fit(select_df)\n",
    "        all_data[column] = le.transform(select_df)\n",
    "    all_data = all_data.drop(id_name,axis=1)\n",
    "    train_df = all_data[all_data[\"is_train\"]==1].drop(\"is_train\",axis=1)\n",
    "    test_df = all_data[all_data[\"is_train\"]==0].drop(\"is_train\",axis=1)\n",
    "    return train_df, test_df, target_df\n",
    "\n",
    "def objective(trial):\n",
    "    # optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    scores = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(param, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(X_eval)\n",
    "        pred_labels = np.rint(preds)\n",
    "        score = accuracy_score(y_eval, pred_labels)\n",
    "        scores.append(score)\n",
    "    return mean(scores)\n",
    "\n",
    "def make_prediction(params):\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    test_preds = []\n",
    "    for tr_inds, val_inds in kf.split(X_train):\n",
    "        X_tr, y_tr = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y_train.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(params, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(Y_test)\n",
    "        test_preds.append(preds)\n",
    "    return list(np.sum(np.array(test_preds),axis=0))\n",
    "\n",
    "def to_csv():\n",
    "    submission = pd.DataFrame()\n",
    "    submission[id_name] = test_df[id_name]\n",
    "    submission[y_train.columns[0]] = test_preds\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    # return submission\n",
    "\n",
    "def main():\n",
    "    train_df, test_df = load_data()\n",
    "    id_name = \"PassengerId\"\n",
    "    X, Y_test, Y = preprocessing(train_df, test_df, id_name)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=2)\n",
    "    test_preds = make_prediction(study.best_params)\n",
    "    print(\"val_score→\"+str(study.best_value))\n",
    "    to_csv()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 16:58:47,186] Finished trial#0 resulted in value: 0.8215115184232. Current best value is 0.8215115184232 with parameters: {'lambda_l1': 0.0410629213560687, 'lambda_l2': 0.0420827881795705, 'num_leaves': 27, 'feature_fraction': 0.48507022763086965, 'bagging_fraction': 0.806331767716109, 'bagging_freq': 2, 'min_child_samples': 19}.\n",
      "[I 2019-12-11 16:58:49,444] Finished trial#1 resulted in value: 0.8282656455966355. Current best value is 0.8282656455966355 with parameters: {'lambda_l1': 0.009996579283141427, 'lambda_l2': 2.1546613695485014e-05, 'num_leaves': 59, 'feature_fraction': 0.5974896029112862, 'bagging_fraction': 0.9033984180208278, 'bagging_freq': 2, 'min_child_samples': 14}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_score→0.8282656455966355\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "    test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocessing(train_df,test_df, id_name):\n",
    "    train_df[\"is_train\"] = 1\n",
    "    test_df[\"is_train\"] = 0\n",
    "    target = set(list(train_df.columns)) ^ set(list(test_df.columns))\n",
    "    target_df = train_df[target]\n",
    "    train_df = train_df.drop(target,axis=1)\n",
    "    all_data = pd.concat([train_df,test_df])\n",
    "    # objectカラムの取得\n",
    "    change_columns =[]\n",
    "    for index_name, dtype in zip(list(train_df.dtypes.index),list(train_df.dtypes.values)):\n",
    "        if  str(dtype) =='object':\n",
    "            change_columns.append(index_name)\n",
    "    train_df[change_columns] = list(train_df[change_columns].fillna(\"欠損\"))\n",
    "    target_column = train_df[change_columns]\n",
    "    for column in change_columns:\n",
    "        le = LabelEncoder()\n",
    "        select_df = all_data[column].astype(str)\n",
    "        le.fit(select_df)\n",
    "        all_data[column] = le.transform(select_df)\n",
    "    all_data = all_data.drop(id_name,axis=1)\n",
    "    train_df = all_data[all_data[\"is_train\"]==1].drop(\"is_train\",axis=1)\n",
    "    test_df = all_data[all_data[\"is_train\"]==0].drop(\"is_train\",axis=1)\n",
    "    return train_df, test_df, target_df\n",
    "\n",
    "def objective(trial):\n",
    "    # optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    scores = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(param, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(X_eval)\n",
    "        pred_labels = np.rint(preds)\n",
    "        score = accuracy_score(y_eval, pred_labels)\n",
    "        scores.append(score)\n",
    "    return mean(scores)\n",
    "\n",
    "def make_prediction(params):\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    test_preds = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_tr, y_tr = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(params, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(Y_test)\n",
    "        test_preds.append(preds)\n",
    "    return list(np.sum(np.array(test_preds),axis=0))\n",
    "\n",
    "def to_csv():\n",
    "    submission = pd.DataFrame()\n",
    "    submission[id_name] = test_df[id_name]\n",
    "    submission[y_train.columns[0]] = test_preds\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_df, test_df = load_data()\n",
    "    id_name = \"PassengerId\"\n",
    "    X, Y_test, Y = preprocessing(train_df, test_df, id_name)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=2)\n",
    "    test_preds = make_prediction(study.best_params)\n",
    "    print(\"val_score→\"+str(study.best_value))\n",
    "    to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:03:03,396] Finished trial#0 resulted in value: 0.8248634737304626. Current best value is 0.8248634737304626 with parameters: {'lambda_l1': 8.391185371922389e-05, 'lambda_l2': 0.22957964356011817, 'num_leaves': 100, 'feature_fraction': 0.9050349829051887, 'bagging_fraction': 0.950857016647558, 'bagging_freq': 6, 'min_child_samples': 59}.\n",
      "[I 2019-12-11 17:03:04,451] Finished trial#1 resulted in value: 0.8170045822610006. Current best value is 0.8248634737304626 with parameters: {'lambda_l1': 8.391185371922389e-05, 'lambda_l2': 0.22957964356011817, 'num_leaves': 100, 'feature_fraction': 0.9050349829051887, 'bagging_fraction': 0.950857016647558, 'bagging_freq': 6, 'min_child_samples': 59}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_score→0.8248634737304626\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "    test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocessing(train_df,test_df, id_name):\n",
    "    train_df[\"is_train\"] = 1\n",
    "    test_df[\"is_train\"] = 0\n",
    "    target = set(list(train_df.columns)) ^ set(list(test_df.columns))\n",
    "    target_df = train_df[target]\n",
    "    train_df = train_df.drop(target,axis=1)\n",
    "    all_data = pd.concat([train_df,test_df])\n",
    "    # objectカラムの取得\n",
    "    change_columns =[]\n",
    "    for index_name, dtype in zip(list(train_df.dtypes.index),list(train_df.dtypes.values)):\n",
    "        if  str(dtype) =='object':\n",
    "            change_columns.append(index_name)\n",
    "    train_df[change_columns] = list(train_df[change_columns].fillna(\"欠損\"))\n",
    "    target_column = train_df[change_columns]\n",
    "    for column in change_columns:\n",
    "        le = LabelEncoder()\n",
    "        select_df = all_data[column].astype(str)\n",
    "        le.fit(select_df)\n",
    "        all_data[column] = le.transform(select_df)\n",
    "    all_data = all_data.drop(id_name,axis=1)\n",
    "    train_df = all_data[all_data[\"is_train\"]==1].drop(\"is_train\",axis=1)\n",
    "    test_df = all_data[all_data[\"is_train\"]==0].drop(\"is_train\",axis=1)\n",
    "    return train_df, test_df, target_df\n",
    "\n",
    "def objective(trial):\n",
    "    # optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    scores = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(param, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(X_eval)\n",
    "        pred_labels = np.rint(preds)\n",
    "        score = accuracy_score(y_eval, pred_labels)\n",
    "        scores.append(score)\n",
    "    return mean(scores)\n",
    "\n",
    "def make_prediction(params):\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    test_preds = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_tr, y_tr = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(params, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(Y_test)\n",
    "        test_preds.append(preds)\n",
    "    return list(np.sum(np.array(test_preds),axis=0))\n",
    "\n",
    "def to_csv():\n",
    "    submission = pd.DataFrame()\n",
    "    submission[id_name] = test_df[id_name]\n",
    "    submission[Y.columns[0]] = test_preds\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_df, test_df = load_data()\n",
    "    id_name = \"PassengerId\"\n",
    "    X, Y_test, Y = preprocessing(train_df, test_df, id_name)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=2)\n",
    "    test_preds = make_prediction(study.best_params)\n",
    "    print(\"val_score→\"+str(study.best_value))\n",
    "    to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:04,687] Finished trial#0 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.00976786167451293, 'lambda_l2': 0.1290934220799596, 'num_leaves': 57, 'feature_fraction': 0.7613732027534676, 'bagging_fraction': 0.5744022343599056, 'bagging_freq': 6, 'min_child_samples': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:05,296] Finished trial#1 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 9.829111058576442e-07, 'lambda_l2': 4.606908184658166, 'num_leaves': 176, 'feature_fraction': 0.5370511802502533, 'bagging_fraction': 0.7991571336097336, 'bagging_freq': 7, 'min_child_samples': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:05,912] Finished trial#2 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 3.520264771902169e-07, 'lambda_l2': 1.2314232149104836e-08, 'num_leaves': 9, 'feature_fraction': 0.6305761903373731, 'bagging_fraction': 0.5057119424850077, 'bagging_freq': 7, 'min_child_samples': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:06,513] Finished trial#3 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 4.098214619329436e-08, 'lambda_l2': 2.0796079699016583, 'num_leaves': 221, 'feature_fraction': 0.4705289162694189, 'bagging_fraction': 0.7179338893394098, 'bagging_freq': 1, 'min_child_samples': 96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:07,123] Finished trial#4 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.018798106552958892, 'lambda_l2': 0.4438844679756404, 'num_leaves': 130, 'feature_fraction': 0.4087578446447019, 'bagging_fraction': 0.4981043579049056, 'bagging_freq': 5, 'min_child_samples': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:07,786] Finished trial#5 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 1.4515513285074841, 'lambda_l2': 9.128289611137914, 'num_leaves': 167, 'feature_fraction': 0.5467231637405177, 'bagging_fraction': 0.9790919084974511, 'bagging_freq': 6, 'min_child_samples': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:08,480] Finished trial#6 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.04208681339156813, 'lambda_l2': 1.694974603122027, 'num_leaves': 66, 'feature_fraction': 0.9111935557718831, 'bagging_fraction': 0.5526119101983702, 'bagging_freq': 7, 'min_child_samples': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:09,110] Finished trial#7 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.009166497323205324, 'lambda_l2': 1.0883098569505605e-08, 'num_leaves': 255, 'feature_fraction': 0.6886973001926843, 'bagging_fraction': 0.766786684297835, 'bagging_freq': 1, 'min_child_samples': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:09,812] Finished trial#8 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 2.335781363382292e-08, 'lambda_l2': 1.2475917047546524e-07, 'num_leaves': 75, 'feature_fraction': 0.5122573218619579, 'bagging_fraction': 0.6042880565033847, 'bagging_freq': 5, 'min_child_samples': 63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:10,490] Finished trial#9 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 2.162306536124477, 'lambda_l2': 0.0016720744452640422, 'num_leaves': 40, 'feature_fraction': 0.8369235335915376, 'bagging_fraction': 0.9031516265830776, 'bagging_freq': 3, 'min_child_samples': 93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:11,163] Finished trial#10 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 3.015485122233966e-05, 'lambda_l2': 5.39957001886167e-05, 'num_leaves': 6, 'feature_fraction': 0.6157251949165216, 'bagging_fraction': 0.43529260479956655, 'bagging_freq': 3, 'min_child_samples': 77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:11,765] Finished trial#11 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.00022125574888966665, 'lambda_l2': 0.006130128323316965, 'num_leaves': 98, 'feature_fraction': 0.41657180284058415, 'bagging_fraction': 0.6383036986457159, 'bagging_freq': 3, 'min_child_samples': 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:12,444] Finished trial#12 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 9.456017775488789, 'lambda_l2': 9.417556872547324e-06, 'num_leaves': 116, 'feature_fraction': 0.7869450626559701, 'bagging_fraction': 0.8410663064183245, 'bagging_freq': 2, 'min_child_samples': 57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:13,084] Finished trial#13 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.3491474650010659, 'lambda_l2': 0.030261178208129628, 'num_leaves': 21, 'feature_fraction': 0.9878037308862052, 'bagging_fraction': 0.7150903492417279, 'bagging_freq': 4, 'min_child_samples': 80}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:13,697] Finished trial#14 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.0008590002326940313, 'lambda_l2': 2.792820426696893e-06, 'num_leaves': 154, 'feature_fraction': 0.6179846667658326, 'bagging_fraction': 0.43088274120624315, 'bagging_freq': 2, 'min_child_samples': 76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:14,349] Finished trial#15 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.21357889119807874, 'lambda_l2': 0.0002646235567414324, 'num_leaves': 208, 'feature_fraction': 0.701969868060154, 'bagging_fraction': 0.6742750690508645, 'bagging_freq': 4, 'min_child_samples': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:15,009] Finished trial#16 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.3761649385952134, 'lambda_l2': 0.03280226402699094, 'num_leaves': 29, 'feature_fraction': 0.9728893001914042, 'bagging_fraction': 0.7266354837879722, 'bagging_freq': 4, 'min_child_samples': 82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:15,659] Finished trial#17 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.0007628922066360733, 'lambda_l2': 1.4559337030122249e-06, 'num_leaves': 155, 'feature_fraction': 0.6066228159411085, 'bagging_fraction': 0.4162911005104169, 'bagging_freq': 2, 'min_child_samples': 69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:16,293] Finished trial#18 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.1371873252882541, 'lambda_l2': 0.0001946303375565574, 'num_leaves': 205, 'feature_fraction': 0.7061703835064488, 'bagging_fraction': 0.6611501715066237, 'bagging_freq': 5, 'min_child_samples': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:16,972] Finished trial#19 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 3.1211364346485424, 'lambda_l2': 0.015486758678630185, 'num_leaves': 34, 'feature_fraction': 0.9941085392499249, 'bagging_fraction': 0.877952853377982, 'bagging_freq': 4, 'min_child_samples': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:17,613] Finished trial#20 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 1.912720459744273e-05, 'lambda_l2': 2.814178667472014e-07, 'num_leaves': 101, 'feature_fraction': 0.5742223223987121, 'bagging_fraction': 0.47659768108402095, 'bagging_freq': 2, 'min_child_samples': 69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:18,247] Finished trial#21 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.05160368319747741, 'lambda_l2': 0.0003899353199001493, 'num_leaves': 206, 'feature_fraction': 0.6756015090629072, 'bagging_fraction': 0.6657532487904166, 'bagging_freq': 5, 'min_child_samples': 38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:18,937] Finished trial#22 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 8.839412581925494, 'lambda_l2': 0.004207557648302616, 'num_leaves': 83, 'feature_fraction': 0.8937019223637053, 'bagging_fraction': 0.931294117605758, 'bagging_freq': 3, 'min_child_samples': 48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:19,547] Finished trial#23 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 1.006698775974491e-05, 'lambda_l2': 5.9561914515069936e-08, 'num_leaves': 111, 'feature_fraction': 0.5659796914909923, 'bagging_fraction': 0.48192809676438464, 'bagging_freq': 1, 'min_child_samples': 55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:20,216] Finished trial#24 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.00412800693108206, 'lambda_l2': 3.7265145470554246e-05, 'num_leaves': 241, 'feature_fraction': 0.4722760550935031, 'bagging_fraction': 0.6146684977785248, 'bagging_freq': 6, 'min_child_samples': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:20,860] Finished trial#25 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 4.100712571622676, 'lambda_l2': 0.00190006550806587, 'num_leaves': 88, 'feature_fraction': 0.9088094275623935, 'bagging_fraction': 0.9716740213857418, 'bagging_freq': 3, 'min_child_samples': 48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:21,475] Finished trial#26 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 5.370491271050239e-06, 'lambda_l2': 0.1605334263836347, 'num_leaves': 128, 'feature_fraction': 0.4768103074832313, 'bagging_fraction': 0.5578178548004524, 'bagging_freq': 1, 'min_child_samples': 58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:22,110] Finished trial#27 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 0.0032861829925461767, 'lambda_l2': 2.0559701671882483e-05, 'num_leaves': 52, 'feature_fraction': 0.4528970370496347, 'bagging_fraction': 0.5723099935747089, 'bagging_freq': 6, 'min_child_samples': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:22,756] Finished trial#28 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'lambda_l1': 1.0054806342804425, 'lambda_l2': 0.0011545002041276258, 'num_leaves': 53, 'feature_fraction': 0.7881303348101888, 'bagging_fraction': 0.9684376309214346, 'bagging_freq': 3, 'min_child_samples': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 17:17:23,413] Finished trial#29 resulted in value: 39038905866.37397. Current best value is 39038905866.37397 with parameters: {'lambda_l1': 0.3732283768904134, 'lambda_l2': 0.0398278591638978, 'num_leaves': 59, 'feature_fraction': 0.5636595595976339, 'bagging_fraction': 0.6323649528870036, 'bagging_freq': 3, 'min_child_samples': 48}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_score→39038905866.37397\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"house_datasets/train.csv\")\n",
    "    test_df = pd.read_csv(\"house_datasets/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocessing(train_df,test_df, id_name):\n",
    "    train_df[\"is_train\"] = 1\n",
    "    test_df[\"is_train\"] = 0\n",
    "    target = set(list(train_df.columns)) ^ set(list(test_df.columns))\n",
    "    target_df = train_df[target]\n",
    "    train_df = train_df.drop(target,axis=1)\n",
    "    all_data = pd.concat([train_df,test_df])\n",
    "    # objectカラムの取得\n",
    "    change_columns =[]\n",
    "    for index_name, dtype in zip(list(train_df.dtypes.index),list(train_df.dtypes.values)):\n",
    "        if  str(dtype) =='object':\n",
    "            change_columns.append(index_name)\n",
    "    train_df[change_columns] = list(train_df[change_columns].fillna(\"欠損\"))\n",
    "    target_column = train_df[change_columns]\n",
    "    for column in change_columns:\n",
    "        le = LabelEncoder()\n",
    "        select_df = all_data[column].astype(str)\n",
    "        le.fit(select_df)\n",
    "        all_data[column] = le.transform(select_df)\n",
    "    all_data = all_data.drop(id_name,axis=1)\n",
    "    train_df = all_data[all_data[\"is_train\"]==1].drop(\"is_train\",axis=1)\n",
    "    test_df = all_data[all_data[\"is_train\"]==0].drop(\"is_train\",axis=1)\n",
    "    return train_df, test_df, target_df\n",
    "\n",
    "def objective(trial):\n",
    "    # optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "    print(param)\n",
    "\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    scores = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(param, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(X_eval)\n",
    "        pred_labels = np.rint(preds)\n",
    "        score = mean_squared_error(y_eval, pred_labels)\n",
    "        scores.append(score)\n",
    "    return mean(scores)\n",
    "\n",
    "def make_prediction(params):\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    test_preds = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_tr, y_tr = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "        lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
    "        model = lgb.train(params, lgb_train, valid_sets=lgb_eval, verbose_eval=False)\n",
    "        preds = model.predict(Y_test)\n",
    "        test_preds.append(preds)\n",
    "    return list(np.sum(np.array(test_preds),axis=0))\n",
    "\n",
    "def to_csv():\n",
    "    submission = pd.DataFrame()\n",
    "    submission[id_name] = test_df[id_name]\n",
    "    submission[Y.columns[0]] = test_preds\n",
    "    submission.to_csv(\"classify_submission.csv\", index=False)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_df, test_df = load_data()\n",
    "    id_name = \"Id\"\n",
    "    X, Y_test, Y = preprocessing(train_df, test_df, id_name)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=30)\n",
    "    test_preds = make_prediction(study.best_params)\n",
    "    print(\"val_score→\"+str(study.best_value))\n",
    "    to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 0.0006366732455576157,\n",
       " 'lambda_l2': 0.5434592970214148,\n",
       " 'num_leaves': 188,\n",
       " 'feature_fraction': 0.7052767511832432,\n",
       " 'bagging_fraction': 0.8140017738784788,\n",
       " 'bagging_freq': 6,\n",
       " 'min_child_samples': 34}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8204506936162199"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for tr_inds, val_inds in kf.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>816</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>422</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>649</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Name  Sex   Age  SibSp  Parch  Ticket     Fare  Cabin  \\\n",
       "0            1       3   155    1  22.0      1      0     720   7.2500    186   \n",
       "1            2       1   286    0  38.0      1      0     816  71.2833    106   \n",
       "2            3       3   523    0  26.0      0      0     914   7.9250    186   \n",
       "3            4       1   422    0  35.0      1      0      65  53.1000     70   \n",
       "4            5       3    22    1  35.0      0      0     649   8.0500    186   \n",
       "\n",
       "   Embarked  \n",
       "0         2  \n",
       "1         0  \n",
       "2         2  \n",
       "3         2  \n",
       "4         2  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    scores = []\n",
    "    print(structure_params)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(X)):\n",
    "        tr_x, tr_y = X[tr_inds],Y[tr_inds]\n",
    "        vl_x, vl_y = X[val_inds],Y[val_inds]\n",
    "        gbm = lgb.train(param, dtrain)\n",
    "        preds = gbm.predict(test_x)\n",
    "        pred_labels = np.rint(preds)\n",
    "        score = accuracy_score(test_y, pred_labels)\n",
    "        scores.append(score)\n",
    "    return mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 20:35:00,244] Finished trial#0 resulted in value: 0.8035842068922227. Current best value is 0.8035842068922227 with parameters: {'lambda_l1': 0.2672638076707509, 'lambda_l2': 0.0015885266596271889, 'num_leaves': 186, 'feature_fraction': 0.40844140963336517, 'bagging_fraction': 0.7395204488916367, 'bagging_freq': 2, 'min_child_samples': 86}.\n",
      "[I 2019-12-11 20:35:00,913] Finished trial#1 resulted in value: 0.7923419747661792. Current best value is 0.7923419747661792 with parameters: {'lambda_l1': 0.14555331012540598, 'lambda_l2': 1.4099140599129005e-07, 'num_leaves': 239, 'feature_fraction': 0.4087073243050536, 'bagging_fraction': 0.7336875423402733, 'bagging_freq': 6, 'min_child_samples': 100}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   5   8  14  27  30  31  34  37  40  55  60  62  75  77  79  85  97\n",
      " 101 103 113 141 142 144 145 150 158 175 181 193 196 200 202 214 215 222\n",
      " 230 231 236 247 249 251 252 255 262 264 266 267 270 278 279 285 293 294\n",
      " 298 299 301 310 311 312 316 317 318 319 342 346 350 352 356 362 367 372\n",
      " 380 384 389 390 395 397 399 412 413 418 425 432 440 458 474 477 483 484\n",
      " 487 489 494 495 496 500 501 503 505 511 513 516 519 522 523 530 531 535\n",
      " 538 542 545 561 564 566 567 570 587 596 609 612 614 619 627 631 632 634\n",
      " 635 638 642 643 644 648 654 655 656 658 666 676 681 683 686 693 694 700\n",
      " 704 708 712 715 725 726 728 740 750 760 762 764 766 768 771 778 780 784\n",
      " 796 803 808 815 818 819 822 833 837 838 839 848 877 880 883 887 890]\n",
      "[1]\tvalid_0's binary_logloss: 0.652849\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.637663\n",
      "[3]\tvalid_0's binary_logloss: 0.62469\n",
      "[4]\tvalid_0's binary_logloss: 0.61603\n",
      "[5]\tvalid_0's binary_logloss: 0.609481\n",
      "[6]\tvalid_0's binary_logloss: 0.603139\n",
      "[7]\tvalid_0's binary_logloss: 0.594024\n",
      "[8]\tvalid_0's binary_logloss: 0.567493\n",
      "[9]\tvalid_0's binary_logloss: 0.561168\n",
      "[10]\tvalid_0's binary_logloss: 0.554648\n",
      "[11]\tvalid_0's binary_logloss: 0.547984\n",
      "[12]\tvalid_0's binary_logloss: 0.527766\n",
      "[13]\tvalid_0's binary_logloss: 0.523401\n",
      "[14]\tvalid_0's binary_logloss: 0.506399\n",
      "[15]\tvalid_0's binary_logloss: 0.504713\n",
      "[16]\tvalid_0's binary_logloss: 0.490128\n",
      "[17]\tvalid_0's binary_logloss: 0.485835\n",
      "[18]\tvalid_0's binary_logloss: 0.474074\n",
      "[19]\tvalid_0's binary_logloss: 0.469816\n",
      "[20]\tvalid_0's binary_logloss: 0.465433\n",
      "[21]\tvalid_0's binary_logloss: 0.462182\n",
      "[22]\tvalid_0's binary_logloss: 0.453724\n",
      "[23]\tvalid_0's binary_logloss: 0.4463\n",
      "[24]\tvalid_0's binary_logloss: 0.443829\n",
      "[25]\tvalid_0's binary_logloss: 0.43754\n",
      "[26]\tvalid_0's binary_logloss: 0.42861\n",
      "[27]\tvalid_0's binary_logloss: 0.421191\n",
      "[28]\tvalid_0's binary_logloss: 0.420496\n",
      "[29]\tvalid_0's binary_logloss: 0.417487\n",
      "[30]\tvalid_0's binary_logloss: 0.413957\n",
      "[31]\tvalid_0's binary_logloss: 0.409282\n",
      "[32]\tvalid_0's binary_logloss: 0.407711\n",
      "[33]\tvalid_0's binary_logloss: 0.404487\n",
      "[34]\tvalid_0's binary_logloss: 0.402019\n",
      "[35]\tvalid_0's binary_logloss: 0.400632\n",
      "[36]\tvalid_0's binary_logloss: 0.397895\n",
      "[37]\tvalid_0's binary_logloss: 0.394699\n",
      "[38]\tvalid_0's binary_logloss: 0.393835\n",
      "[39]\tvalid_0's binary_logloss: 0.391378\n",
      "[40]\tvalid_0's binary_logloss: 0.390559\n",
      "[41]\tvalid_0's binary_logloss: 0.389169\n",
      "[42]\tvalid_0's binary_logloss: 0.38846\n",
      "[43]\tvalid_0's binary_logloss: 0.387651\n",
      "[44]\tvalid_0's binary_logloss: 0.385316\n",
      "[45]\tvalid_0's binary_logloss: 0.383536\n",
      "[46]\tvalid_0's binary_logloss: 0.381571\n",
      "[47]\tvalid_0's binary_logloss: 0.380066\n",
      "[48]\tvalid_0's binary_logloss: 0.379476\n",
      "[49]\tvalid_0's binary_logloss: 0.378263\n",
      "[50]\tvalid_0's binary_logloss: 0.376925\n",
      "[51]\tvalid_0's binary_logloss: 0.375308\n",
      "[52]\tvalid_0's binary_logloss: 0.372696\n",
      "[53]\tvalid_0's binary_logloss: 0.371391\n",
      "[54]\tvalid_0's binary_logloss: 0.369586\n",
      "[55]\tvalid_0's binary_logloss: 0.369641\n",
      "[56]\tvalid_0's binary_logloss: 0.36888\n",
      "[57]\tvalid_0's binary_logloss: 0.367944\n",
      "[58]\tvalid_0's binary_logloss: 0.36653\n",
      "[59]\tvalid_0's binary_logloss: 0.36561\n",
      "[60]\tvalid_0's binary_logloss: 0.365709\n",
      "[61]\tvalid_0's binary_logloss: 0.365468\n",
      "[62]\tvalid_0's binary_logloss: 0.363846\n",
      "[63]\tvalid_0's binary_logloss: 0.362979\n",
      "[64]\tvalid_0's binary_logloss: 0.362348\n",
      "[65]\tvalid_0's binary_logloss: 0.362395\n",
      "[66]\tvalid_0's binary_logloss: 0.361846\n",
      "[67]\tvalid_0's binary_logloss: 0.361353\n",
      "[68]\tvalid_0's binary_logloss: 0.361201\n",
      "[69]\tvalid_0's binary_logloss: 0.3609\n",
      "[70]\tvalid_0's binary_logloss: 0.360147\n",
      "[71]\tvalid_0's binary_logloss: 0.360032\n",
      "[72]\tvalid_0's binary_logloss: 0.359898\n",
      "[73]\tvalid_0's binary_logloss: 0.359241\n",
      "[74]\tvalid_0's binary_logloss: 0.355581\n",
      "[75]\tvalid_0's binary_logloss: 0.352704\n",
      "[76]\tvalid_0's binary_logloss: 0.351749\n",
      "[77]\tvalid_0's binary_logloss: 0.350823\n",
      "[78]\tvalid_0's binary_logloss: 0.34844\n",
      "[79]\tvalid_0's binary_logloss: 0.349146\n",
      "[80]\tvalid_0's binary_logloss: 0.349209\n",
      "[81]\tvalid_0's binary_logloss: 0.349035\n",
      "[82]\tvalid_0's binary_logloss: 0.349973\n",
      "[83]\tvalid_0's binary_logloss: 0.350977\n",
      "[84]\tvalid_0's binary_logloss: 0.350967\n",
      "[85]\tvalid_0's binary_logloss: 0.349935\n",
      "[86]\tvalid_0's binary_logloss: 0.348716\n",
      "[87]\tvalid_0's binary_logloss: 0.34791\n",
      "[88]\tvalid_0's binary_logloss: 0.346992\n",
      "[89]\tvalid_0's binary_logloss: 0.346194\n",
      "[90]\tvalid_0's binary_logloss: 0.34525\n",
      "[91]\tvalid_0's binary_logloss: 0.344124\n",
      "[92]\tvalid_0's binary_logloss: 0.343547\n",
      "[93]\tvalid_0's binary_logloss: 0.342362\n",
      "[94]\tvalid_0's binary_logloss: 0.341664\n",
      "[95]\tvalid_0's binary_logloss: 0.341242\n",
      "[96]\tvalid_0's binary_logloss: 0.339974\n",
      "[97]\tvalid_0's binary_logloss: 0.33974\n",
      "[98]\tvalid_0's binary_logloss: 0.338049\n",
      "[99]\tvalid_0's binary_logloss: 0.337868\n",
      "[100]\tvalid_0's binary_logloss: 0.337841\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.337841\n",
      "[  2  10  12  17  18  20  21  35  39  45  48  49  50  52  54  64  65  66\n",
      "  68  71  76  78  81  92 105 109 116 118 122 124 127 140 154 155 156 157\n",
      " 159 161 162 165 167 170 172 187 188 198 204 210 211 235 238 239 240 241\n",
      " 242 243 250 253 258 261 263 268 271 272 283 304 306 308 320 331 333 337\n",
      " 338 344 345 351 358 363 364 366 378 379 382 386 391 402 403 406 408 416\n",
      " 424 428 434 439 443 447 451 453 456 457 462 465 467 471 475 476 481 482\n",
      " 485 491 492 521 524 526 532 533 549 553 573 578 580 585 588 592 597 615\n",
      " 618 620 646 647 652 653 671 672 674 680 695 698 701 706 718 720 724 727\n",
      " 731 738 742 744 752 753 769 785 786 788 799 800 811 813 817 820 823 832\n",
      " 841 843 851 852 857 862 866 870 875 876 878 881 882 885 886 889]\n",
      "[1]\tvalid_0's binary_logloss: 0.653139\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.645055\n",
      "[3]\tvalid_0's binary_logloss: 0.638926\n",
      "[4]\tvalid_0's binary_logloss: 0.63359\n",
      "[5]\tvalid_0's binary_logloss: 0.629191\n",
      "[6]\tvalid_0's binary_logloss: 0.624331\n",
      "[7]\tvalid_0's binary_logloss: 0.62075\n",
      "[8]\tvalid_0's binary_logloss: 0.595956\n",
      "[9]\tvalid_0's binary_logloss: 0.592964\n",
      "[10]\tvalid_0's binary_logloss: 0.589785\n",
      "[11]\tvalid_0's binary_logloss: 0.588098\n",
      "[12]\tvalid_0's binary_logloss: 0.570082\n",
      "[13]\tvalid_0's binary_logloss: 0.568317\n",
      "[14]\tvalid_0's binary_logloss: 0.55507\n",
      "[15]\tvalid_0's binary_logloss: 0.551872\n",
      "[16]\tvalid_0's binary_logloss: 0.540784\n",
      "[17]\tvalid_0's binary_logloss: 0.538683\n",
      "[18]\tvalid_0's binary_logloss: 0.53004\n",
      "[19]\tvalid_0's binary_logloss: 0.529524\n",
      "[20]\tvalid_0's binary_logloss: 0.52904\n",
      "[21]\tvalid_0's binary_logloss: 0.528938\n",
      "[22]\tvalid_0's binary_logloss: 0.520586\n",
      "[23]\tvalid_0's binary_logloss: 0.514259\n",
      "[24]\tvalid_0's binary_logloss: 0.513129\n",
      "[25]\tvalid_0's binary_logloss: 0.506639\n",
      "[26]\tvalid_0's binary_logloss: 0.501703\n",
      "[27]\tvalid_0's binary_logloss: 0.496046\n",
      "[28]\tvalid_0's binary_logloss: 0.495794\n",
      "[29]\tvalid_0's binary_logloss: 0.495774\n",
      "[30]\tvalid_0's binary_logloss: 0.490974\n",
      "[31]\tvalid_0's binary_logloss: 0.486232\n",
      "[32]\tvalid_0's binary_logloss: 0.485237\n",
      "[33]\tvalid_0's binary_logloss: 0.482211\n",
      "[34]\tvalid_0's binary_logloss: 0.480314\n",
      "[35]\tvalid_0's binary_logloss: 0.479295\n",
      "[36]\tvalid_0's binary_logloss: 0.477006\n",
      "[37]\tvalid_0's binary_logloss: 0.477149\n",
      "[38]\tvalid_0's binary_logloss: 0.474661\n",
      "[39]\tvalid_0's binary_logloss: 0.474231\n",
      "[40]\tvalid_0's binary_logloss: 0.473329\n",
      "[41]\tvalid_0's binary_logloss: 0.471933\n",
      "[42]\tvalid_0's binary_logloss: 0.470905\n",
      "[43]\tvalid_0's binary_logloss: 0.469147\n",
      "[44]\tvalid_0's binary_logloss: 0.468074\n",
      "[45]\tvalid_0's binary_logloss: 0.466828\n",
      "[46]\tvalid_0's binary_logloss: 0.466898\n",
      "[47]\tvalid_0's binary_logloss: 0.466983\n",
      "[48]\tvalid_0's binary_logloss: 0.465868\n",
      "[49]\tvalid_0's binary_logloss: 0.465007\n",
      "[50]\tvalid_0's binary_logloss: 0.463467\n",
      "[51]\tvalid_0's binary_logloss: 0.462302\n",
      "[52]\tvalid_0's binary_logloss: 0.461052\n",
      "[53]\tvalid_0's binary_logloss: 0.4605\n",
      "[54]\tvalid_0's binary_logloss: 0.460129\n",
      "[55]\tvalid_0's binary_logloss: 0.460054\n",
      "[56]\tvalid_0's binary_logloss: 0.457887\n",
      "[57]\tvalid_0's binary_logloss: 0.457666\n",
      "[58]\tvalid_0's binary_logloss: 0.455508\n",
      "[59]\tvalid_0's binary_logloss: 0.454681\n",
      "[60]\tvalid_0's binary_logloss: 0.452765\n",
      "[61]\tvalid_0's binary_logloss: 0.451987\n",
      "[62]\tvalid_0's binary_logloss: 0.450815\n",
      "[63]\tvalid_0's binary_logloss: 0.448805\n",
      "[64]\tvalid_0's binary_logloss: 0.448037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65]\tvalid_0's binary_logloss: 0.447433\n",
      "[66]\tvalid_0's binary_logloss: 0.447345\n",
      "[67]\tvalid_0's binary_logloss: 0.445639\n",
      "[68]\tvalid_0's binary_logloss: 0.445024\n",
      "[69]\tvalid_0's binary_logloss: 0.443968\n",
      "[70]\tvalid_0's binary_logloss: 0.443872\n",
      "[71]\tvalid_0's binary_logloss: 0.442917\n",
      "[72]\tvalid_0's binary_logloss: 0.442385\n",
      "[73]\tvalid_0's binary_logloss: 0.440524\n",
      "[74]\tvalid_0's binary_logloss: 0.437154\n",
      "[75]\tvalid_0's binary_logloss: 0.436513\n",
      "[76]\tvalid_0's binary_logloss: 0.435214\n",
      "[77]\tvalid_0's binary_logloss: 0.434062\n",
      "[78]\tvalid_0's binary_logloss: 0.433848\n",
      "[79]\tvalid_0's binary_logloss: 0.433012\n",
      "[80]\tvalid_0's binary_logloss: 0.43202\n",
      "[81]\tvalid_0's binary_logloss: 0.431016\n",
      "[82]\tvalid_0's binary_logloss: 0.430465\n",
      "[83]\tvalid_0's binary_logloss: 0.429123\n",
      "[84]\tvalid_0's binary_logloss: 0.429218\n",
      "[85]\tvalid_0's binary_logloss: 0.429247\n",
      "[86]\tvalid_0's binary_logloss: 0.4279\n",
      "[87]\tvalid_0's binary_logloss: 0.428436\n",
      "[88]\tvalid_0's binary_logloss: 0.428912\n",
      "[89]\tvalid_0's binary_logloss: 0.428587\n",
      "[90]\tvalid_0's binary_logloss: 0.428441\n",
      "[91]\tvalid_0's binary_logloss: 0.426859\n",
      "[92]\tvalid_0's binary_logloss: 0.426409\n",
      "[93]\tvalid_0's binary_logloss: 0.425608\n",
      "[94]\tvalid_0's binary_logloss: 0.425372\n",
      "[95]\tvalid_0's binary_logloss: 0.425092\n",
      "[96]\tvalid_0's binary_logloss: 0.423807\n",
      "[97]\tvalid_0's binary_logloss: 0.423286\n",
      "[98]\tvalid_0's binary_logloss: 0.423519\n",
      "[99]\tvalid_0's binary_logloss: 0.423309\n",
      "[100]\tvalid_0's binary_logloss: 0.422423\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.422423\n",
      "[  0   3   6   7  15  22  26  38  46  51  56  63  74  89  90  96 100 102\n",
      " 104 107 108 112 125 126 132 133 134 135 137 153 171 173 178 179 185 186\n",
      " 190 194 205 206 208 213 218 220 223 224 225 229 233 237 245 246 259 295\n",
      " 302 303 309 313 315 325 327 330 332 334 339 343 353 354 355 360 361 365\n",
      " 369 374 375 385 392 400 401 404 407 409 415 417 419 420 422 427 435 436\n",
      " 441 452 454 460 466 468 473 478 479 493 497 499 502 506 518 520 527 529\n",
      " 546 548 557 558 563 569 571 572 576 583 586 603 604 605 613 622 625 626\n",
      " 628 630 640 650 657 661 662 669 670 678 682 687 688 691 702 703 710 713\n",
      " 721 722 729 733 735 737 743 759 761 765 772 782 787 789 790 798 806 807\n",
      " 810 812 816 821 825 827 844 853 855 859 860 861 864 873 884 888]\n",
      "[1]\tvalid_0's binary_logloss: 0.624287\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.611531\n",
      "[3]\tvalid_0's binary_logloss: 0.601479\n",
      "[4]\tvalid_0's binary_logloss: 0.591938\n",
      "[5]\tvalid_0's binary_logloss: 0.584869\n",
      "[6]\tvalid_0's binary_logloss: 0.578125\n",
      "[7]\tvalid_0's binary_logloss: 0.570498\n",
      "[8]\tvalid_0's binary_logloss: 0.546061\n",
      "[9]\tvalid_0's binary_logloss: 0.539179\n",
      "[10]\tvalid_0's binary_logloss: 0.534734\n",
      "[11]\tvalid_0's binary_logloss: 0.531044\n",
      "[12]\tvalid_0's binary_logloss: 0.512374\n",
      "[13]\tvalid_0's binary_logloss: 0.508386\n",
      "[14]\tvalid_0's binary_logloss: 0.493059\n",
      "[15]\tvalid_0's binary_logloss: 0.49174\n",
      "[16]\tvalid_0's binary_logloss: 0.48044\n",
      "[17]\tvalid_0's binary_logloss: 0.477276\n",
      "[18]\tvalid_0's binary_logloss: 0.466722\n",
      "[19]\tvalid_0's binary_logloss: 0.464112\n",
      "[20]\tvalid_0's binary_logloss: 0.46308\n",
      "[21]\tvalid_0's binary_logloss: 0.461578\n",
      "[22]\tvalid_0's binary_logloss: 0.45421\n",
      "[23]\tvalid_0's binary_logloss: 0.447655\n",
      "[24]\tvalid_0's binary_logloss: 0.445827\n",
      "[25]\tvalid_0's binary_logloss: 0.43929\n",
      "[26]\tvalid_0's binary_logloss: 0.43029\n",
      "[27]\tvalid_0's binary_logloss: 0.423823\n",
      "[28]\tvalid_0's binary_logloss: 0.421465\n",
      "[29]\tvalid_0's binary_logloss: 0.419299\n",
      "[30]\tvalid_0's binary_logloss: 0.415615\n",
      "[31]\tvalid_0's binary_logloss: 0.412393\n",
      "[32]\tvalid_0's binary_logloss: 0.411165\n",
      "[33]\tvalid_0's binary_logloss: 0.408545\n",
      "[34]\tvalid_0's binary_logloss: 0.406685\n",
      "[35]\tvalid_0's binary_logloss: 0.404481\n",
      "[36]\tvalid_0's binary_logloss: 0.403321\n",
      "[37]\tvalid_0's binary_logloss: 0.403823\n",
      "[38]\tvalid_0's binary_logloss: 0.402421\n",
      "[39]\tvalid_0's binary_logloss: 0.401266\n",
      "[40]\tvalid_0's binary_logloss: 0.399027\n",
      "[41]\tvalid_0's binary_logloss: 0.398982\n",
      "[42]\tvalid_0's binary_logloss: 0.398697\n",
      "[43]\tvalid_0's binary_logloss: 0.397395\n",
      "[44]\tvalid_0's binary_logloss: 0.39525\n",
      "[45]\tvalid_0's binary_logloss: 0.392378\n",
      "[46]\tvalid_0's binary_logloss: 0.392014\n",
      "[47]\tvalid_0's binary_logloss: 0.391419\n",
      "[48]\tvalid_0's binary_logloss: 0.389813\n",
      "[49]\tvalid_0's binary_logloss: 0.388741\n",
      "[50]\tvalid_0's binary_logloss: 0.387831\n",
      "[51]\tvalid_0's binary_logloss: 0.385773\n",
      "[52]\tvalid_0's binary_logloss: 0.385077\n",
      "[53]\tvalid_0's binary_logloss: 0.383909\n",
      "[54]\tvalid_0's binary_logloss: 0.383644\n",
      "[55]\tvalid_0's binary_logloss: 0.382256\n",
      "[56]\tvalid_0's binary_logloss: 0.381265\n",
      "[57]\tvalid_0's binary_logloss: 0.379339\n",
      "[58]\tvalid_0's binary_logloss: 0.377695\n",
      "[59]\tvalid_0's binary_logloss: 0.37563\n",
      "[60]\tvalid_0's binary_logloss: 0.374504\n",
      "[61]\tvalid_0's binary_logloss: 0.373785\n",
      "[62]\tvalid_0's binary_logloss: 0.371173\n",
      "[63]\tvalid_0's binary_logloss: 0.369874\n",
      "[64]\tvalid_0's binary_logloss: 0.368035\n",
      "[65]\tvalid_0's binary_logloss: 0.366042\n",
      "[66]\tvalid_0's binary_logloss: 0.364047\n",
      "[67]\tvalid_0's binary_logloss: 0.362409\n",
      "[68]\tvalid_0's binary_logloss: 0.361348\n",
      "[69]\tvalid_0's binary_logloss: 0.36085\n",
      "[70]\tvalid_0's binary_logloss: 0.360144\n",
      "[71]\tvalid_0's binary_logloss: 0.359187\n",
      "[72]\tvalid_0's binary_logloss: 0.358915\n",
      "[73]\tvalid_0's binary_logloss: 0.358528\n",
      "[74]\tvalid_0's binary_logloss: 0.354544\n",
      "[75]\tvalid_0's binary_logloss: 0.354311\n",
      "[76]\tvalid_0's binary_logloss: 0.353683\n",
      "[77]\tvalid_0's binary_logloss: 0.353366\n",
      "[78]\tvalid_0's binary_logloss: 0.353552\n",
      "[79]\tvalid_0's binary_logloss: 0.352023\n",
      "[80]\tvalid_0's binary_logloss: 0.349363\n",
      "[81]\tvalid_0's binary_logloss: 0.347549\n",
      "[82]\tvalid_0's binary_logloss: 0.346275\n",
      "[83]\tvalid_0's binary_logloss: 0.345313\n",
      "[84]\tvalid_0's binary_logloss: 0.34346\n",
      "[85]\tvalid_0's binary_logloss: 0.343052\n",
      "[86]\tvalid_0's binary_logloss: 0.341461\n",
      "[87]\tvalid_0's binary_logloss: 0.341283\n",
      "[88]\tvalid_0's binary_logloss: 0.340551\n",
      "[89]\tvalid_0's binary_logloss: 0.339095\n",
      "[90]\tvalid_0's binary_logloss: 0.338839\n",
      "[91]\tvalid_0's binary_logloss: 0.339455\n",
      "[92]\tvalid_0's binary_logloss: 0.339611\n",
      "[93]\tvalid_0's binary_logloss: 0.341191\n",
      "[94]\tvalid_0's binary_logloss: 0.341881\n",
      "[95]\tvalid_0's binary_logloss: 0.342066\n",
      "[96]\tvalid_0's binary_logloss: 0.341494\n",
      "[97]\tvalid_0's binary_logloss: 0.341207\n",
      "[98]\tvalid_0's binary_logloss: 0.341495\n",
      "[99]\tvalid_0's binary_logloss: 0.340207\n",
      "[100]\tvalid_0's binary_logloss: 0.339464\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.338839\n",
      "[  4  13  16  24  25  29  33  44  59  61  67  69  73  83  88  93 106 110\n",
      " 111 114 117 120 121 129 136 138 146 149 152 160 163 164 166 168 176 189\n",
      " 191 195 199 207 212 216 217 219 221 228 232 234 254 274 276 281 282 284\n",
      " 287 289 290 297 300 322 326 329 336 340 341 347 348 349 357 376 381 393\n",
      " 394 405 414 421 426 429 433 437 438 445 446 449 455 463 464 469 470 480\n",
      " 490 498 504 507 508 509 514 517 525 528 534 536 539 540 541 547 552 556\n",
      " 568 575 577 579 582 584 590 591 593 595 601 602 608 616 623 624 636 641\n",
      " 645 649 651 663 664 665 667 668 673 679 685 689 692 711 716 717 730 732\n",
      " 736 741 745 746 747 748 749 751 757 758 767 770 775 781 783 792 793 794\n",
      " 795 801 805 809 814 824 828 831 834 846 856 863 868 869 872 879]\n",
      "[1]\tvalid_0's binary_logloss: 0.652517\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.645342\n",
      "[3]\tvalid_0's binary_logloss: 0.636508\n",
      "[4]\tvalid_0's binary_logloss: 0.630139\n",
      "[5]\tvalid_0's binary_logloss: 0.625252\n",
      "[6]\tvalid_0's binary_logloss: 0.619301\n",
      "[7]\tvalid_0's binary_logloss: 0.612502\n",
      "[8]\tvalid_0's binary_logloss: 0.587883\n",
      "[9]\tvalid_0's binary_logloss: 0.582514\n",
      "[10]\tvalid_0's binary_logloss: 0.577366\n",
      "[11]\tvalid_0's binary_logloss: 0.573366\n",
      "[12]\tvalid_0's binary_logloss: 0.555403\n",
      "[13]\tvalid_0's binary_logloss: 0.55273\n",
      "[14]\tvalid_0's binary_logloss: 0.53933\n",
      "[15]\tvalid_0's binary_logloss: 0.536133\n",
      "[16]\tvalid_0's binary_logloss: 0.524681\n",
      "[17]\tvalid_0's binary_logloss: 0.522694\n",
      "[18]\tvalid_0's binary_logloss: 0.514269\n",
      "[19]\tvalid_0's binary_logloss: 0.512066\n",
      "[20]\tvalid_0's binary_logloss: 0.510514\n",
      "[21]\tvalid_0's binary_logloss: 0.509809\n",
      "[22]\tvalid_0's binary_logloss: 0.503957\n",
      "[23]\tvalid_0's binary_logloss: 0.498252\n",
      "[24]\tvalid_0's binary_logloss: 0.49709\n",
      "[25]\tvalid_0's binary_logloss: 0.491162\n",
      "[26]\tvalid_0's binary_logloss: 0.485942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tvalid_0's binary_logloss: 0.482238\n",
      "[28]\tvalid_0's binary_logloss: 0.480488\n",
      "[29]\tvalid_0's binary_logloss: 0.479519\n",
      "[30]\tvalid_0's binary_logloss: 0.475769\n",
      "[31]\tvalid_0's binary_logloss: 0.471597\n",
      "[32]\tvalid_0's binary_logloss: 0.470261\n",
      "[33]\tvalid_0's binary_logloss: 0.468791\n",
      "[34]\tvalid_0's binary_logloss: 0.467409\n",
      "[35]\tvalid_0's binary_logloss: 0.465498\n",
      "[36]\tvalid_0's binary_logloss: 0.464996\n",
      "[37]\tvalid_0's binary_logloss: 0.46453\n",
      "[38]\tvalid_0's binary_logloss: 0.463269\n",
      "[39]\tvalid_0's binary_logloss: 0.46249\n",
      "[40]\tvalid_0's binary_logloss: 0.461152\n",
      "[41]\tvalid_0's binary_logloss: 0.459734\n",
      "[42]\tvalid_0's binary_logloss: 0.458255\n",
      "[43]\tvalid_0's binary_logloss: 0.458204\n",
      "[44]\tvalid_0's binary_logloss: 0.458173\n",
      "[45]\tvalid_0's binary_logloss: 0.457139\n",
      "[46]\tvalid_0's binary_logloss: 0.457025\n",
      "[47]\tvalid_0's binary_logloss: 0.456664\n",
      "[48]\tvalid_0's binary_logloss: 0.456858\n",
      "[49]\tvalid_0's binary_logloss: 0.456043\n",
      "[50]\tvalid_0's binary_logloss: 0.455707\n",
      "[51]\tvalid_0's binary_logloss: 0.45615\n",
      "[52]\tvalid_0's binary_logloss: 0.456367\n",
      "[53]\tvalid_0's binary_logloss: 0.456519\n",
      "[54]\tvalid_0's binary_logloss: 0.455904\n",
      "[55]\tvalid_0's binary_logloss: 0.455014\n",
      "[56]\tvalid_0's binary_logloss: 0.451856\n",
      "[57]\tvalid_0's binary_logloss: 0.452792\n",
      "[58]\tvalid_0's binary_logloss: 0.45023\n",
      "[59]\tvalid_0's binary_logloss: 0.447247\n",
      "[60]\tvalid_0's binary_logloss: 0.444698\n",
      "[61]\tvalid_0's binary_logloss: 0.444297\n",
      "[62]\tvalid_0's binary_logloss: 0.444335\n",
      "[63]\tvalid_0's binary_logloss: 0.444034\n",
      "[64]\tvalid_0's binary_logloss: 0.443712\n",
      "[65]\tvalid_0's binary_logloss: 0.444133\n",
      "[66]\tvalid_0's binary_logloss: 0.442784\n",
      "[67]\tvalid_0's binary_logloss: 0.44099\n",
      "[68]\tvalid_0's binary_logloss: 0.441118\n",
      "[69]\tvalid_0's binary_logloss: 0.439976\n",
      "[70]\tvalid_0's binary_logloss: 0.439399\n",
      "[71]\tvalid_0's binary_logloss: 0.439002\n",
      "[72]\tvalid_0's binary_logloss: 0.438567\n",
      "[73]\tvalid_0's binary_logloss: 0.437815\n",
      "[74]\tvalid_0's binary_logloss: 0.436411\n",
      "[75]\tvalid_0's binary_logloss: 0.434551\n",
      "[76]\tvalid_0's binary_logloss: 0.435461\n",
      "[77]\tvalid_0's binary_logloss: 0.434349\n",
      "[78]\tvalid_0's binary_logloss: 0.432563\n",
      "[79]\tvalid_0's binary_logloss: 0.431965\n",
      "[80]\tvalid_0's binary_logloss: 0.432378\n",
      "[81]\tvalid_0's binary_logloss: 0.430288\n",
      "[82]\tvalid_0's binary_logloss: 0.429381\n",
      "[83]\tvalid_0's binary_logloss: 0.4284\n",
      "[84]\tvalid_0's binary_logloss: 0.42879\n",
      "[85]\tvalid_0's binary_logloss: 0.42892\n",
      "[86]\tvalid_0's binary_logloss: 0.427195\n",
      "[87]\tvalid_0's binary_logloss: 0.426604\n",
      "[88]\tvalid_0's binary_logloss: 0.426505\n",
      "[89]\tvalid_0's binary_logloss: 0.425082\n",
      "[90]\tvalid_0's binary_logloss: 0.424168\n",
      "[91]\tvalid_0's binary_logloss: 0.423065\n",
      "[92]\tvalid_0's binary_logloss: 0.422694\n",
      "[93]\tvalid_0's binary_logloss: 0.422118\n",
      "[94]\tvalid_0's binary_logloss: 0.42173\n",
      "[95]\tvalid_0's binary_logloss: 0.421475\n",
      "[96]\tvalid_0's binary_logloss: 0.421268\n",
      "[97]\tvalid_0's binary_logloss: 0.419637\n",
      "[98]\tvalid_0's binary_logloss: 0.418605\n",
      "[99]\tvalid_0's binary_logloss: 0.41874\n",
      "[100]\tvalid_0's binary_logloss: 0.418118\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.418118\n",
      "[  9  11  19  23  28  32  36  41  42  43  47  53  57  58  70  72  80  82\n",
      "  84  86  87  91  94  95  98  99 115 119 123 128 130 131 139 143 147 148\n",
      " 151 169 174 177 180 182 183 184 192 197 201 203 209 226 227 244 248 256\n",
      " 257 260 265 269 273 275 277 280 286 288 291 292 296 305 307 314 321 323\n",
      " 324 328 335 359 368 370 371 373 377 383 387 388 396 398 410 411 423 430\n",
      " 431 442 444 448 450 459 461 472 486 488 510 512 515 537 543 544 550 551\n",
      " 554 555 559 560 562 565 574 581 589 594 598 599 600 606 607 610 611 617\n",
      " 621 629 633 637 639 659 660 675 677 684 690 696 697 699 705 707 709 714\n",
      " 719 723 734 739 754 755 756 763 773 774 776 777 779 791 797 802 804 826\n",
      " 829 830 835 836 840 842 845 847 849 850 854 858 865 867 871 874]\n",
      "[1]\tvalid_0's binary_logloss: 0.683884\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.672403\n",
      "[3]\tvalid_0's binary_logloss: 0.660806\n",
      "[4]\tvalid_0's binary_logloss: 0.651543\n",
      "[5]\tvalid_0's binary_logloss: 0.643336\n",
      "[6]\tvalid_0's binary_logloss: 0.637668\n",
      "[7]\tvalid_0's binary_logloss: 0.630054\n",
      "[8]\tvalid_0's binary_logloss: 0.598754\n",
      "[9]\tvalid_0's binary_logloss: 0.592496\n",
      "[10]\tvalid_0's binary_logloss: 0.588841\n",
      "[11]\tvalid_0's binary_logloss: 0.585177\n",
      "[12]\tvalid_0's binary_logloss: 0.56166\n",
      "[13]\tvalid_0's binary_logloss: 0.559284\n",
      "[14]\tvalid_0's binary_logloss: 0.539753\n",
      "[15]\tvalid_0's binary_logloss: 0.53835\n",
      "[16]\tvalid_0's binary_logloss: 0.52348\n",
      "[17]\tvalid_0's binary_logloss: 0.521131\n",
      "[18]\tvalid_0's binary_logloss: 0.507507\n",
      "[19]\tvalid_0's binary_logloss: 0.505181\n",
      "[20]\tvalid_0's binary_logloss: 0.502257\n",
      "[21]\tvalid_0's binary_logloss: 0.500991\n",
      "[22]\tvalid_0's binary_logloss: 0.489623\n",
      "[23]\tvalid_0's binary_logloss: 0.481318\n",
      "[24]\tvalid_0's binary_logloss: 0.479653\n",
      "[25]\tvalid_0's binary_logloss: 0.471506\n",
      "[26]\tvalid_0's binary_logloss: 0.464489\n",
      "[27]\tvalid_0's binary_logloss: 0.458875\n",
      "[28]\tvalid_0's binary_logloss: 0.457552\n",
      "[29]\tvalid_0's binary_logloss: 0.456794\n",
      "[30]\tvalid_0's binary_logloss: 0.45156\n",
      "[31]\tvalid_0's binary_logloss: 0.445718\n",
      "[32]\tvalid_0's binary_logloss: 0.444643\n",
      "[33]\tvalid_0's binary_logloss: 0.439124\n",
      "[34]\tvalid_0's binary_logloss: 0.435527\n",
      "[35]\tvalid_0's binary_logloss: 0.433692\n",
      "[36]\tvalid_0's binary_logloss: 0.428893\n",
      "[37]\tvalid_0's binary_logloss: 0.426687\n",
      "[38]\tvalid_0's binary_logloss: 0.423792\n",
      "[39]\tvalid_0's binary_logloss: 0.42354\n",
      "[40]\tvalid_0's binary_logloss: 0.420959\n",
      "[41]\tvalid_0's binary_logloss: 0.419139\n",
      "[42]\tvalid_0's binary_logloss: 0.41886\n",
      "[43]\tvalid_0's binary_logloss: 0.416959\n",
      "[44]\tvalid_0's binary_logloss: 0.415574\n",
      "[45]\tvalid_0's binary_logloss: 0.414079\n",
      "[46]\tvalid_0's binary_logloss: 0.412843\n",
      "[47]\tvalid_0's binary_logloss: 0.412671\n",
      "[48]\tvalid_0's binary_logloss: 0.411788\n",
      "[49]\tvalid_0's binary_logloss: 0.409833\n",
      "[50]\tvalid_0's binary_logloss: 0.407814\n",
      "[51]\tvalid_0's binary_logloss: 0.405495\n",
      "[52]\tvalid_0's binary_logloss: 0.405301\n",
      "[53]\tvalid_0's binary_logloss: 0.402892\n",
      "[54]\tvalid_0's binary_logloss: 0.400934\n",
      "[55]\tvalid_0's binary_logloss: 0.400516\n",
      "[56]\tvalid_0's binary_logloss: 0.400195\n",
      "[57]\tvalid_0's binary_logloss: 0.398527\n",
      "[58]\tvalid_0's binary_logloss: 0.398208\n",
      "[59]\tvalid_0's binary_logloss: 0.397189\n",
      "[60]\tvalid_0's binary_logloss: 0.39837\n",
      "[61]\tvalid_0's binary_logloss: 0.397859\n",
      "[62]\tvalid_0's binary_logloss: 0.397483\n",
      "[63]\tvalid_0's binary_logloss: 0.397394\n",
      "[64]\tvalid_0's binary_logloss: 0.397026\n",
      "[65]\tvalid_0's binary_logloss: 0.396388\n",
      "[66]\tvalid_0's binary_logloss: 0.395206\n",
      "[67]\tvalid_0's binary_logloss: 0.395175\n",
      "[68]\tvalid_0's binary_logloss: 0.394763\n",
      "[69]\tvalid_0's binary_logloss: 0.39321\n",
      "[70]\tvalid_0's binary_logloss: 0.392831\n",
      "[71]\tvalid_0's binary_logloss: 0.39191\n",
      "[72]\tvalid_0's binary_logloss: 0.3908\n",
      "[73]\tvalid_0's binary_logloss: 0.388909\n",
      "[74]\tvalid_0's binary_logloss: 0.388742\n",
      "[75]\tvalid_0's binary_logloss: 0.387991\n",
      "[76]\tvalid_0's binary_logloss: 0.386781\n",
      "[77]\tvalid_0's binary_logloss: 0.385893\n",
      "[78]\tvalid_0's binary_logloss: 0.385512\n",
      "[79]\tvalid_0's binary_logloss: 0.385026\n",
      "[80]\tvalid_0's binary_logloss: 0.384389\n",
      "[81]\tvalid_0's binary_logloss: 0.384137\n",
      "[82]\tvalid_0's binary_logloss: 0.384076\n",
      "[83]\tvalid_0's binary_logloss: 0.383746\n",
      "[84]\tvalid_0's binary_logloss: 0.383498\n",
      "[85]\tvalid_0's binary_logloss: 0.382922\n",
      "[86]\tvalid_0's binary_logloss: 0.382108\n",
      "[87]\tvalid_0's binary_logloss: 0.381931\n",
      "[88]\tvalid_0's binary_logloss: 0.381638\n",
      "[89]\tvalid_0's binary_logloss: 0.381353\n",
      "[90]\tvalid_0's binary_logloss: 0.381909\n",
      "[91]\tvalid_0's binary_logloss: 0.380599\n",
      "[92]\tvalid_0's binary_logloss: 0.379546\n",
      "[93]\tvalid_0's binary_logloss: 0.379191\n",
      "[94]\tvalid_0's binary_logloss: 0.378513\n",
      "[95]\tvalid_0's binary_logloss: 0.37773\n",
      "[96]\tvalid_0's binary_logloss: 0.378068\n",
      "[97]\tvalid_0's binary_logloss: 0.378671\n",
      "[98]\tvalid_0's binary_logloss: 0.378232\n",
      "[99]\tvalid_0's binary_logloss: 0.377823\n",
      "[100]\tvalid_0's binary_logloss: 0.376889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.376889\n",
      "val_score→0.7923419747661792\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "    test_df = pd.read_csv(\"datasets/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocessing(train_df,test_df, id_name):\n",
    "    train_df[\"is_train\"] = 1\n",
    "    test_df[\"is_train\"] = 0\n",
    "    target = set(list(train_df.columns)) ^ set(list(test_df.columns))\n",
    "    target_df = train_df[target]\n",
    "    train_df = train_df.drop(target,axis=1)\n",
    "    all_data = pd.concat([train_df,test_df])\n",
    "    # objectカラムの取得\n",
    "    change_columns =[]\n",
    "    for index_name, dtype in zip(list(train_df.dtypes.index),list(train_df.dtypes.values)):\n",
    "        if  str(dtype) =='object':\n",
    "            change_columns.append(index_name)\n",
    "    train_df[change_columns] = list(train_df[change_columns].fillna(\"欠損\"))\n",
    "    target_column = train_df[change_columns]\n",
    "    for column in change_columns:\n",
    "        le = LabelEncoder()\n",
    "        select_df = all_data[column].astype(str)\n",
    "        le.fit(select_df)\n",
    "        all_data[column] = le.transform(select_df)\n",
    "    all_data = all_data.drop(id_name,axis=1)\n",
    "    train_df = all_data[all_data[\"is_train\"]==1].drop(\"is_train\",axis=1)\n",
    "    test_df = all_data[all_data[\"is_train\"]==0].drop(\"is_train\",axis=1)\n",
    "    return train_df, test_df, target_df\n",
    "\n",
    "def objective(trial):\n",
    "    # optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    scores = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train,y_train,early_stopping_rounds=10,eval_set=[[X_eval, y_eval]],verbose=0)\n",
    "        preds = model.predict(X_eval)\n",
    "        pred_labels = np.rint(preds)\n",
    "        score = accuracy_score(y_eval, pred_labels)\n",
    "        scores.append(score)\n",
    "    return mean(scores)\n",
    "\n",
    "def make_prediction(params):\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    test_preds = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = X.columns\n",
    "    n_fold = 1\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_tr, y_tr = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train,y_train,early_stopping_rounds=10,eval_set=[[X_eval, y_eval]])\n",
    "        preds = model.predict(Y_test)\n",
    "        test_preds.append(preds)\n",
    "    feature_importance_df[\"feature\"] = feats\n",
    "    feature_importance_df[\"importance\"] = model.feature_importances_\n",
    "    return list(np.sum(np.array(test_preds),axis=0)),feature_importance_df\n",
    "\n",
    "def to_csv():\n",
    "    submission = pd.DataFrame()\n",
    "    submission[id_name] = test_df[id_name]\n",
    "    submission[Y.columns[0]] = test_preds\n",
    "    submission.to_csv(\"classify_submission.csv\", index=False)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_df, test_df = load_data()\n",
    "    id_name = \"PassengerId\"\n",
    "    X, Y_test, Y = preprocessing(train_df, test_df, id_name)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=2)\n",
    "    test_preds,feature_importance_df = make_prediction(study.best_params)\n",
    "    print(\"val_score→\"+str(study.best_value))\n",
    "    to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-11 20:40:12,670] Finished trial#0 resulted in value: 0.0. Current best value is 0.0 with parameters: {'lambda_l1': 8.984782016185405e-05, 'lambda_l2': 5.737920679394895e-06, 'num_leaves': 73, 'feature_fraction': 0.6395302472894522, 'bagging_fraction': 0.6081379325901611, 'bagging_freq': 3, 'min_child_samples': 84}.\n",
      "[I 2019-12-11 20:40:14,834] Finished trial#1 resulted in value: 0.0. Current best value is 0.0 with parameters: {'lambda_l1': 8.984782016185405e-05, 'lambda_l2': 5.737920679394895e-06, 'num_leaves': 73, 'feature_fraction': 0.6395302472894522, 'bagging_fraction': 0.6081379325901611, 'bagging_freq': 3, 'min_child_samples': 84}.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [68500, 79500, 82500, 84900, 87500, 89471, 90350, 92900, 99900, 101000, 104000, 105900, 106250, 107900, 108959, 116050, 119200, 123600, 128200, 134450, 136000, 136905, 137900, 139500, 142953, 145500, 145900, 148800, 149350, 150500, 155900, 156500, 158500, 163900, 164990, 165600, 175900, 178900, 181500, 181900, 182900, 183900, 185900, 186000, 187750, 188500, 193500, 193879, 194201, 198500, 200500, 200624, 202665, 206300, 213250, 213490, 216837, 224500, 229456, 230500, 233000, 239900, 243000, 245350, 248900, 249700, 251000, 263000, 265000, 277500, 282922, 301000, 306000, 313000, 316600, 319900, 324000, 367294, 370878, 372500, 385000, 386250, 392000, 403000, 412500, 415298, 438780, 538000, 555000, 745000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-9f3d434ef638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_importance_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_score→\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-9f3d434ef638>\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtest_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    784\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                     \u001b[0meval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 49\u001b[0;31m                              % str(diff))\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [68500, 79500, 82500, 84900, 87500, 89471, 90350, 92900, 99900, 101000, 104000, 105900, 106250, 107900, 108959, 116050, 119200, 123600, 128200, 134450, 136000, 136905, 137900, 139500, 142953, 145500, 145900, 148800, 149350, 150500, 155900, 156500, 158500, 163900, 164990, 165600, 175900, 178900, 181500, 181900, 182900, 183900, 185900, 186000, 187750, 188500, 193500, 193879, 194201, 198500, 200500, 200624, 202665, 206300, 213250, 213490, 216837, 224500, 229456, 230500, 233000, 239900, 243000, 245350, 248900, 249700, 251000, 263000, 265000, 277500, 282922, 301000, 306000, 313000, 316600, 319900, 324000, 367294, 370878, 372500, 385000, 386250, 392000, 403000, 412500, 415298, 438780, 538000, 555000, 745000]"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"house_datasets/train.csv\")\n",
    "    test_df = pd.read_csv(\"house_datasets/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocessing(train_df,test_df, id_name):\n",
    "    train_df[\"is_train\"] = 1\n",
    "    test_df[\"is_train\"] = 0\n",
    "    target = set(list(train_df.columns)) ^ set(list(test_df.columns))\n",
    "    target_df = train_df[target]\n",
    "    train_df = train_df.drop(target,axis=1)\n",
    "    all_data = pd.concat([train_df,test_df])\n",
    "    # objectカラムの取得\n",
    "    change_columns =[]\n",
    "    for index_name, dtype in zip(list(train_df.dtypes.index),list(train_df.dtypes.values)):\n",
    "        if  str(dtype) =='object':\n",
    "            change_columns.append(index_name)\n",
    "    train_df[change_columns] = list(train_df[change_columns].fillna(\"欠損\"))\n",
    "    target_column = train_df[change_columns]\n",
    "    for column in change_columns:\n",
    "        le = LabelEncoder()\n",
    "        select_df = all_data[column].astype(str)\n",
    "        le.fit(select_df)\n",
    "        all_data[column] = le.transform(select_df)\n",
    "    all_data = all_data.drop(id_name,axis=1)\n",
    "    train_df = all_data[all_data[\"is_train\"]==1].drop(\"is_train\",axis=1)\n",
    "    test_df = all_data[all_data[\"is_train\"]==0].drop(\"is_train\",axis=1)\n",
    "    return train_df, test_df, target_df\n",
    "\n",
    "def objective(trial):\n",
    "    # optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    scores = []\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_train,y_train,early_stopping_rounds=10,eval_set=[[X_eval, y_eval]],verbose=0)\n",
    "        preds = model.predict(X_eval)\n",
    "        pred_labels = np.rint(preds)\n",
    "        score = accuracy_score(y_eval, pred_labels)\n",
    "        scores.append(score)\n",
    "    return mean(scores)\n",
    "\n",
    "def make_prediction(params):\n",
    "    kfold = KFold(5, random_state = 0, shuffle = True)\n",
    "    test_preds = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = X.columns\n",
    "    n_fold = 1\n",
    "    for tr_inds, val_inds in kfold.split(X):\n",
    "        X_train, y_train = X.iloc[tr_inds],Y.iloc[tr_inds]\n",
    "        X_eval, y_eval = X.iloc[val_inds],Y.iloc[val_inds]\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_train,y_train,early_stopping_rounds=10,eval_set=[[X_eval, y_eval]])\n",
    "        preds = model.predict(Y_test)\n",
    "        test_preds.append(preds)\n",
    "    feature_importance_df[\"feature\"] = feats\n",
    "    feature_importance_df[\"importance\"] = model.feature_importances_\n",
    "    return list(np.sum(np.array(test_preds),axis=0)),feature_importance_df\n",
    "\n",
    "def to_csv():\n",
    "    submission = pd.DataFrame()\n",
    "    submission[id_name] = test_df[id_name]\n",
    "    submission[Y.columns[0]] = test_preds\n",
    "    submission.to_csv(\"classify_submission.csv\", index=False)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_df, test_df = load_data()\n",
    "    id_name = \"Id\"\n",
    "    X, Y_test, Y = preprocessing(train_df, test_df, id_name)\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=2)\n",
    "    test_preds,feature_importance_df = make_prediction(study.best_params)\n",
    "    print(\"val_score→\"+str(study.best_value))\n",
    "    to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Name</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Fare</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Age</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sex</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Embarked</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Parch</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "1      Name          77\n",
       "6    Ticket          76\n",
       "7      Fare          76\n",
       "3       Age          63\n",
       "2       Sex          30\n",
       "8     Cabin          21\n",
       "0    Pclass          18\n",
       "9  Embarked          10\n",
       "4     SibSp           8\n",
       "5     Parch           5"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Name</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Name</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>Name</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>Name</td>\n",
       "      <td>193</td>\n",
       "      <td>4</td>\n",
       "      <td>Name</td>\n",
       "      <td>193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sex</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>Sex</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>Sex</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>Sex</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>Sex</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Age</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>Age</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>Age</td>\n",
       "      <td>231</td>\n",
       "      <td>3</td>\n",
       "      <td>Age</td>\n",
       "      <td>231</td>\n",
       "      <td>4</td>\n",
       "      <td>Age</td>\n",
       "      <td>231</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Parch</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Parch</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Parch</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>Parch</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>Parch</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>221</td>\n",
       "      <td>3</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>221</td>\n",
       "      <td>4</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>221</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Fare</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>Fare</td>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>Fare</td>\n",
       "      <td>215</td>\n",
       "      <td>3</td>\n",
       "      <td>Fare</td>\n",
       "      <td>215</td>\n",
       "      <td>4</td>\n",
       "      <td>Fare</td>\n",
       "      <td>215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>Cabin</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Embarked</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Embarked</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Embarked</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>Embarked</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>Embarked</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance  fold   feature  importance  fold   feature  \\\n",
       "0    Pclass          37     1    Pclass          37     2    Pclass   \n",
       "1      Name         193     1      Name         193     2      Name   \n",
       "2       Sex          47     1       Sex          47     2       Sex   \n",
       "3       Age         231     1       Age         231     2       Age   \n",
       "4     SibSp          21     1     SibSp          21     2     SibSp   \n",
       "5     Parch          11     1     Parch          11     2     Parch   \n",
       "6    Ticket         221     1    Ticket         221     2    Ticket   \n",
       "7      Fare         215     1      Fare         215     2      Fare   \n",
       "8     Cabin          50     1     Cabin          50     2     Cabin   \n",
       "9  Embarked          22     1  Embarked          22     2  Embarked   \n",
       "\n",
       "   importance  fold   feature  importance  fold   feature  importance  fold  \n",
       "0          37     3    Pclass          37     4    Pclass          37     5  \n",
       "1         193     3      Name         193     4      Name         193     5  \n",
       "2          47     3       Sex          47     4       Sex          47     5  \n",
       "3         231     3       Age         231     4       Age         231     5  \n",
       "4          21     3     SibSp          21     4     SibSp          21     5  \n",
       "5          11     3     Parch          11     4     Parch          11     5  \n",
       "6         221     3    Ticket         221     4    Ticket         221     5  \n",
       "7         215     3      Fare         215     4      Fare         215     5  \n",
       "8          50     3     Cabin          50     4     Cabin          50     5  \n",
       "9          22     3  Embarked          22     4  Embarked          22     5  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##今全部一緒だがこれで大丈夫かは要確認する\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = feats\n",
    "fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "fold_importance_df[\"fold\"] = n_fold + 1\n",
    "feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  is_train  \n",
       "0      0         A/5 21171   7.2500   NaN        S         1  \n",
       "1      0          PC 17599  71.2833   C85        C         1  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S         1  \n",
       "3      0            113803  53.1000  C123        S         1  \n",
       "4      0            373450   8.0500   NaN        S         1  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=47)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=47)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            #is_unbalance=True,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=32,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.04,\n",
    "            reg_lambda=0.073,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=40,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "            #scale_pos_weight=11\n",
    "            )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 1000, early_stopping_rounds= 200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
