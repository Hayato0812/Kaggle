{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 82)\n",
      "(1460, 81)\n",
      "(1459, 81)\n",
      "(2919, 82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 0)\n",
      "(2919, 351)\n",
      "(2919, 351)\n",
      "(2919,)\n",
      "(2919, 352)\n",
      "(2919, 314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import csv as csv\n",
    "\n",
    "# /Users/hayatoyamaguchi/Public/kaggle/House Price/house-prices-advanced-regression-techniques\n",
    "\n",
    "path = \"house-prices-advanced-regression-techniques/\"\n",
    "train_df = pd.read_csv(path+\"train.csv\", header=0)\n",
    "test_df = pd.read_csv(path+\"test.csv\", header=0)\n",
    "train_df['WhatIsData'] = 'Train'\n",
    "test_df['WhatIsData'] = 'Test'\n",
    "train_df.tail()\n",
    "\n",
    "drop_train_df = train_df.drop('SalePrice',axis=1)\n",
    "allData = pd.concat([drop_train_df,test_df],axis=0)\n",
    "allData['TotalSF'] = allData['TotalBsmtSF'] + allData['1stFlrSF'] + allData['2ndFlrSF']\n",
    "print(train_df.shape)\n",
    "print(drop_train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(allData.shape)\n",
    "allData[\"LotFrontage\"] = allData.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "na_col_list = allData.isnull().sum()[allData.isnull().sum()>0].sort_values(ascending=False).index.tolist()\n",
    "for row in na_col_list:\n",
    "    if allData[row].dtypes == \"float64\":\n",
    "        allData[row][allData[row].isnull()] = 0\n",
    "    else:\n",
    "        allData[row][allData[row].isnull()] = \"NA\"\n",
    "\n",
    "dropData = allData[allData.columns[allData.columns != \"WhatIsData\"]]\n",
    "\n",
    "data_dummies = pd.get_dummies(dropData)\n",
    "transdropData = pd.concat([dropData,data_dummies],axis=1)\n",
    "\n",
    "transdropData = transdropData.select_dtypes(include=[\"float64\",\"int64\",\"uint8\"])\n",
    "transdropData = transdropData.astype('int')\n",
    "a = transdropData.select_dtypes(include=\"object\")\n",
    "print(a.shape)\n",
    "print(transdropData.shape)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "columns = transdropData.columns.values\n",
    "transdropData_scaled = pd.DataFrame(scaler.fit(transdropData).transform(transdropData),columns=columns)\n",
    "print(transdropData_scaled.shape)\n",
    "print(allData[\"WhatIsData\"].shape)\n",
    "# transAllData = pd.concat([transdropData_scaled,allData[\"WhatIsData\"]],axis=1)\n",
    "\n",
    "transdropData_scaled[\"WhatIsData\"] = list(allData[\"WhatIsData\"])\n",
    "transAllData = transdropData_scaled\n",
    "\n",
    "from sklearn import preprocessing\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(train_df[\"SalePrice\"])\n",
    "type(np.log(train_df[\"SalePrice\"][0]))\n",
    "\n",
    "transAllData2 = transAllData.loc[:,~transAllData.columns.duplicated()]\n",
    "print(transAllData.shape)\n",
    "print(transAllData2.shape)\n",
    "\n",
    "X_train = transAllData2[transAllData2['WhatIsData']=='Train'].drop(['WhatIsData','Id'], axis=1)\n",
    "y_train = np.log(train_df[\"SalePrice\"])\n",
    "X_test = transAllData2[transAllData2['WhatIsData']=='Test'].drop(['WhatIsData','Id'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done using Random Forest\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=80, max_features='auto')\n",
    "rf.fit(X_train, y_train)\n",
    "print('Training done using Random Forest')\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 20,200\n",
    "\n",
    "ranking = np.argsort(-rf.feature_importances_)\n",
    "# f, ax = plt.subplots(figsize=(11, 90))\n",
    "# sns.barplot(x=rf.feature_importances_[ranking], y=X_train.columns.values[ranking], orient='h')\n",
    "# ax.set_xlabel(\"feature importance\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[:,ranking[:37]]\n",
    "X_test = X_test.iloc[:,ranking[:37]]\n",
    "X_train[\"Interaction\"] = X_train[\"TotalSF\"]*X_train[\"OverallQual\"]\n",
    "X_test[\"Interaction\"] = X_test[\"TotalSF\"]*X_test[\"OverallQual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-4ca19fadd47c>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-4ca19fadd47c>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    from sklearn.svm, import SVR\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# XGBoost, RandomForest,SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgbr = xgb.XGBRegressor(max_depth=3,learning_rate=0.1,colsample_bytree=0.6)\n",
    "xgbr.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR(C=3,gamma=0.001)\n",
    "svr.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRlassifier\n",
    "forest = RandomForestRegressor(random_state=0,min_samples_split=10,n_estimators=700)\n",
    "forest.fit(X_train,y_train)\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes = (90, 90),\n",
    "    alpha = 2.75q\n",
    ")\n",
    "\n",
    "\n",
    "##XGboosting,RandomForest,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "param_grid = {\"C\":[1,3,10,30,100,300,100],\"gamma\":[0,0.001,0.003,0.01]}\n",
    "grid_search = GridSearchCV(svr, param_grid,scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.cv_results_ = results\n",
    "# result = pd.DataFrame(pd.concat([results[\"param_C\"],results[\"param_gamma\"],results[\"mean_test_score\"]],axis=1))\n",
    "# result\n",
    "model = SVR(C=3,gamma=0.001)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "time= datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "predictions = np.exp(model.predict(X_test))\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['Id'] = test_df['Id']\n",
    "df_result['SalePrice'] = predictions\n",
    "df_result.to_csv('result.csv'+time,index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X_train_train,X_val,y_train_train,y_val = train_test_split(X_train,y_train, random_state=0)\n",
    "# epochs = [100,200,300,400,500,600,700,800,900,1000,1095]\n",
    "epochs = [50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1095]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for epoch in epochs:\n",
    "    model = RandomForestRegressor(random_state=0,min_samples_split=10,n_estimators=700)\n",
    "    X_train_epoch = X_train_train[:epoch]\n",
    "    y_train_epoch = y_train_train[:epoch]\n",
    "#     print(X_train_epoch.shape)\n",
    "#     print(y_train_epoch.shape)\n",
    "    model.fit(X_train_epoch,y_train_epoch)\n",
    "#     print(forest.score(X_train_epoch,y_train_epoch))\n",
    "#     print(forest.score(X_val,y_val))\n",
    "    train_scores.append(model.score(X_train_epoch,y_train_epoch))\n",
    "    test_scores.append(model.score(X_val,y_val))\n",
    "#     train_scores.append(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#     test_scores.append(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "\n",
    "    if epoch==1095:\n",
    "#             print(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#             print(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "            print(model.score(X_train_epoch,y_train_epoch))\n",
    "            print(model.score(X_val,y_val))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = epochs\n",
    "y0 = train_scores\n",
    "y1 = test_scores\n",
    "fig = plt.figure()\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y0, label='train_scores')\n",
    "plt.plot(x, y1, label='test_scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost, RandomForest,SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgbr = xgb.XGBRegressor(max_depth=3,learning_rate=0.1,colsample_bytree=0.6)\n",
    "xgbr.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR(C=3,gamma=0.001)\n",
    "svr.fit(X_train,y_train)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# forest =RandomForestRegressor(random_state=0,min_samples_split=10,n_estimators=700)\n",
    "# forest.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "##XGboosting,RandomForest,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train2 = pd.DataFrame( {'XGB': reg_xgb.predict(X_train),\n",
    "#      'DL': reg_dl.predict(X_train).ravel(),\n",
    "#      'SVR': reg_svr.predict(X_train),\n",
    "#     })\n",
    "X_train2 = pd.DataFrame({\"XGB\":xgbr.predict(X_train),\"SVR\":svr.predict(X_train),\"RandomForest\":forest.predict(X_train),})\n",
    "X_train2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train2_train,X_val2,y_train2_train,y_val2 = train_test_split(X_train2,y_train,random_state=0)\n",
    "\n",
    "time= datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train2_train,y_train2_train)\n",
    "# reg.score()\n",
    "print(y_train2_train.shape)\n",
    "print(X_train2_train.shape)\n",
    "print(np.sqrt(mean_squared_error(y_train2_train ,reg.predict(X_train2_train))))\n",
    "print(np.sqrt(mean_squared_error(y_val2,reg.predict(X_val2))))\n",
    "\n",
    "# print(reg.coef_)\n",
    "\n",
    "# X_test2 = pd.DataFrame({\"XGB\":xgbr.predict(X_test),\"SVR\":svr.predict(X_test),\"RandomForest\":forest.predict(X_test),})\n",
    "\n",
    "# predictions = np.exp(reg.predict(X_test2))\n",
    "\n",
    "# df_result = pd.DataFrame()\n",
    "# df_result['Id'] = test_df['Id']\n",
    "# df_result['SalePrice'] = predictions\n",
    "# df_result.to_csv('result.csv'+time,index=False)\n",
    "# df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>128211.099070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>157288.336237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>180487.799804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>181641.975367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>189983.817002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1466</td>\n",
       "      <td>183866.440962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1467</td>\n",
       "      <td>172530.086674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1468</td>\n",
       "      <td>175361.022270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1469</td>\n",
       "      <td>187383.777570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1470</td>\n",
       "      <td>115358.722149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471</td>\n",
       "      <td>201092.745094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1472</td>\n",
       "      <td>94595.324946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1473</td>\n",
       "      <td>98901.812397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1474</td>\n",
       "      <td>153079.600152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1475</td>\n",
       "      <td>146596.546724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1476</td>\n",
       "      <td>340632.676572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1477</td>\n",
       "      <td>252707.546966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1478</td>\n",
       "      <td>314072.836635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1479</td>\n",
       "      <td>251786.093247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1480</td>\n",
       "      <td>448609.569648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1481</td>\n",
       "      <td>324223.727492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1482</td>\n",
       "      <td>215125.893806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1483</td>\n",
       "      <td>182233.600262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1484</td>\n",
       "      <td>170681.591369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1485</td>\n",
       "      <td>169648.760086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1486</td>\n",
       "      <td>201042.613892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1487</td>\n",
       "      <td>332100.904215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1488</td>\n",
       "      <td>249607.165387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1489</td>\n",
       "      <td>201143.730743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1490</td>\n",
       "      <td>192133.900378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>2890</td>\n",
       "      <td>79157.123273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>2891</td>\n",
       "      <td>138976.366523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>2892</td>\n",
       "      <td>55975.745529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>2893</td>\n",
       "      <td>98792.001757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2894</td>\n",
       "      <td>57808.850201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2895</td>\n",
       "      <td>296318.250425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2896</td>\n",
       "      <td>289281.184236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2897</td>\n",
       "      <td>192860.094658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2898</td>\n",
       "      <td>158387.424656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2899</td>\n",
       "      <td>246711.411561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2900</td>\n",
       "      <td>162177.533807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2901</td>\n",
       "      <td>188959.396903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2902</td>\n",
       "      <td>188182.063547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2903</td>\n",
       "      <td>322116.448142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2904</td>\n",
       "      <td>354573.613467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>2905</td>\n",
       "      <td>92912.350719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>2906</td>\n",
       "      <td>190422.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>2907</td>\n",
       "      <td>110723.762117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2908</td>\n",
       "      <td>129040.236630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2909</td>\n",
       "      <td>145670.669521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2910</td>\n",
       "      <td>81272.483091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2911</td>\n",
       "      <td>86088.636801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2912</td>\n",
       "      <td>146926.678196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2913</td>\n",
       "      <td>88462.255680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>2914</td>\n",
       "      <td>83750.722555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>84430.500452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>86282.944041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>156865.014164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>112573.240037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>231491.867966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  128211.099070\n",
       "1     1462  157288.336237\n",
       "2     1463  180487.799804\n",
       "3     1464  181641.975367\n",
       "4     1465  189983.817002\n",
       "5     1466  183866.440962\n",
       "6     1467  172530.086674\n",
       "7     1468  175361.022270\n",
       "8     1469  187383.777570\n",
       "9     1470  115358.722149\n",
       "10    1471  201092.745094\n",
       "11    1472   94595.324946\n",
       "12    1473   98901.812397\n",
       "13    1474  153079.600152\n",
       "14    1475  146596.546724\n",
       "15    1476  340632.676572\n",
       "16    1477  252707.546966\n",
       "17    1478  314072.836635\n",
       "18    1479  251786.093247\n",
       "19    1480  448609.569648\n",
       "20    1481  324223.727492\n",
       "21    1482  215125.893806\n",
       "22    1483  182233.600262\n",
       "23    1484  170681.591369\n",
       "24    1485  169648.760086\n",
       "25    1486  201042.613892\n",
       "26    1487  332100.904215\n",
       "27    1488  249607.165387\n",
       "28    1489  201143.730743\n",
       "29    1490  192133.900378\n",
       "...    ...            ...\n",
       "1429  2890   79157.123273\n",
       "1430  2891  138976.366523\n",
       "1431  2892   55975.745529\n",
       "1432  2893   98792.001757\n",
       "1433  2894   57808.850201\n",
       "1434  2895  296318.250425\n",
       "1435  2896  289281.184236\n",
       "1436  2897  192860.094658\n",
       "1437  2898  158387.424656\n",
       "1438  2899  246711.411561\n",
       "1439  2900  162177.533807\n",
       "1440  2901  188959.396903\n",
       "1441  2902  188182.063547\n",
       "1442  2903  322116.448142\n",
       "1443  2904  354573.613467\n",
       "1444  2905   92912.350719\n",
       "1445  2906  190422.090700\n",
       "1446  2907  110723.762117\n",
       "1447  2908  129040.236630\n",
       "1448  2909  145670.669521\n",
       "1449  2910   81272.483091\n",
       "1450  2911   86088.636801\n",
       "1451  2912  146926.678196\n",
       "1452  2913   88462.255680\n",
       "1453  2914   83750.722555\n",
       "1454  2915   84430.500452\n",
       "1455  2916   86282.944041\n",
       "1456  2917  156865.014164\n",
       "1457  2918  112573.240037\n",
       "1458  2919  231491.867966\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datetime import datetime\n",
    "time= datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model = RandomForestRegressor(random_state=0,min_samples_split=10,n_estimators=700)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = np.exp(model.predict(X_test))\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['Id'] = test_df['Id']\n",
    "df_result['SalePrice'] = predictions\n",
    "df_result.to_csv('result.csv'+time,index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c8160942768f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train2_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train2_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# epochs = [100,200,300,400,500,600,700,800,900,1000,1095]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m550\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m650\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m850\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m950\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1050\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1095\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X_train2_train,X_val,y_train2_train,y_val = train_test_split(X_train2,y_train,random_state=0)\n",
    "# epochs = [100,200,300,400,500,600,700,800,900,1000,1095]\n",
    "epochs = [50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1095]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for epoch in epochs:\n",
    "    model =reg = linear_model.LinearRegression()\n",
    "    X_train_epoch = X_train2_train[:epoch]\n",
    "    y_train_epoch = y_train2_train[:epoch]\n",
    "#     print(X_train_epoch.shape)\n",
    "#     print(y_train_epoch.shape)\n",
    "    model.fit(X_train_epoch,y_train_epoch)\n",
    "#     print(forest.score(X_train_epoch,y_train_epoch))\n",
    "#     print(forest.score(X_val,y_val))\n",
    "    train_scores.append(model.score(X_train_epoch,y_train_epoch))\n",
    "    test_scores.append(model.score(X_val,y_val))\n",
    "#     train_scores.append(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#     test_scores.append(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "\n",
    "    if epoch==1095:\n",
    "#             print(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#             print(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "            print(model.score(X_train_epoch,y_train_epoch))\n",
    "            print(model.score(X_val,y_val))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = epochs\n",
    "y0 = train_scores\n",
    "y1 = test_scores\n",
    "fig = plt.figure()\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y0, label='train_scores')\n",
    "plt.plot(x, y1, label='test_scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-66d7a44eaff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlgb_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlgb_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m params = {\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_train' is not defined"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train_train, y_train_train)\n",
    "lgb_eval = lgb.Dataset(X_val,y_val)\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': {'multi_logloss'},\n",
    "        'num_class': 3,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 23,\n",
    "        'min_data_in_leaf': 1,\n",
    "        'num_iteration': 100,\n",
    "        'verbose': 0\n",
    "}\n",
    "\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=50,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8097331431075494\n",
      "-1.346399827607737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_train,X_val,y_train_train,y_val = train_test_split(X_train,y_train, random_state=0)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes = (120, 90),\n",
    "    alpha = 2.75\n",
    ")\n",
    "mlp.fit(X_train_train,y_train_train)\n",
    "print(mlp.score(X_train_train,y_train_train))\n",
    "print(mlp.score(X_val,y_val))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# print(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "# print(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9019721646963677\n",
      "0.808373200943964\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train_train,X_val,y_train_train,y_val = train_test_split(X_train,y_train,random_state=0)\n",
    "epochs = [100,200,300,400,500,600,700,800,900,1000,1095]\n",
    "# epochs = [50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1095]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for epoch in epochs:\n",
    "    model = Ridge(alpha=100)\n",
    "    X_train_epoch = X_train_train[:epoch]\n",
    "    y_train_epoch = y_train_train[:epoch]\n",
    "#     print(X_train_epoch.shape)\n",
    "#     print(y_train_epoch.shape)\n",
    "    model.fit(X_train_epoch,y_train_epoch)\n",
    "#     print(forest.score(X_train_epoch,y_train_epoch))\n",
    "#     print(forest.score(X_val,y_val))\n",
    "    train_scores.append(model.score(X_train_epoch,y_train_epoch))\n",
    "    test_scores.append(model.score(X_val,y_val))\n",
    "#     train_scores.append(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#     test_scores.append(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "\n",
    "    if epoch==1095:\n",
    "#             print(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#             print(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "            print(model.score(X_train_epoch,y_train_epoch))\n",
    "            print(model.score(X_val,y_val))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = epochs\n",
    "y0 = train_scores\n",
    "y1 = test_scores\n",
    "fig = plt.figure()\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y0, label='train_scores')\n",
    "plt.plot(x, y1, label='test_scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095,)\n",
      "(1095, 38)\n",
      "0.14077324295235968\n",
      "0.19434828022649228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "X_train_train,X_val,y_train_train,y_val = train_test_split(X_train,y_train,random_state=0)\n",
    "\n",
    "time= datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train_train,y_train_train)\n",
    "# reg.score()\n",
    "print(y_train_train.shape)\n",
    "print(X_train_train.shape)\n",
    "print(np.sqrt(mean_squared_error(y_train_train ,reg.predict(X_train_train))))\n",
    "print(np.sqrt(mean_squared_error(y_val,reg.predict(X_val))))\n",
    "\n",
    "\n",
    "xgbr = xgb.XGBRegressor(max_depth=3,learning_rate=0.1,colsample_bytree=0.6)\n",
    "xgbr.fit(X_train_train,y_train_train)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR(C=3,gamma=0.001)\n",
    "svr.fit(X_train_train,y_train_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(random_state=0,min_samples_split=10,n_estimators=700)\n",
    "forest.fit(X_train_train,y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008087338368757413\n",
      "0.01112257796109073\n",
      "[ 0.13133503 -0.1753609   0.05303806]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train2 = pd.DataFrame({\"XGB\":xgbr.predict(X_train_train),\"SVR\":svr.predict(X_train_train),\"RandomForest\":forest.predict(X_train_train),})\n",
    "X_val2 = pd.DataFrame({\"XGB\":xgbr.predict(X_val),\"SVR\":svr.predict(X_val),\"RandomForest\":forest.predict(X_val),})\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# X_train2_train,X_val,y_train2_train,y_val = train_test_split(X_train2,y_train,random_state=0)\n",
    "# epochs = [100,200,300,400,500,600,700,800,900,1000,1095]\n",
    "epochs = [50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1095]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for epoch in epochs:\n",
    "    model =reg = linear_model.LinearRegression()\n",
    "    X_train_epoch = X_train2[:epoch]\n",
    "    y_train_epoch = y_train[:epoch]\n",
    "#     print(X_train_epoch.shape)\n",
    "#     print(y_train_epoch.shape)\n",
    "    model.fit(X_train_epoch,y_train_epoch)\n",
    "#     print(forest.score(X_train_epoch,y_train_epoch))\n",
    "#     print(forest.score(X_val,y_val))\n",
    "    train_scores.append(model.score(X_train_epoch,y_train_epoch))\n",
    "    test_scores.append(model.score(X_val2,y_val))\n",
    "#     train_scores.append(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#     test_scores.append(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "\n",
    "    if epoch==1095:\n",
    "#             print(np.sqrt(mean_squared_error(y_train_train ,model.predict(X_train_train))))\n",
    "#             print(np.sqrt(mean_squared_error(y_val,model.predict(X_val))))\n",
    "            print(model.score(X_train_epoch,y_train_epoch))\n",
    "            print(model.score(X_val2,y_val))\n",
    "\n",
    "print(model.coef_)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = epochs\n",
    "y0 = train_scores\n",
    "y1 = test_scores\n",
    "fig = plt.figure()\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(x, y0, label='train_scores')\n",
    "plt.plot(x, y1, label='test_scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRlassifier\n",
    "\n",
    "xgbr = xgb.XGBRegressor(max_depth=3,learning_rate=0.1,colsample_bytree=0.6)\n",
    "xgbr.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "svr = SVR(C=3,gamma=0.001)\n",
    "svr.fit(X_train,y_train)\n",
    "\n",
    "forest = RandomForestRegressor(random_state=0,min_samples_split=10,n_estimators=700)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'regressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c3e01b904517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           \u001b[0muse_probas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                           \u001b[0maverage_probas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                           meta_regressor=lr)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tain_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tain_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'regressor'"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "clf = StackingRegressor(regressor=[xgbr,svr,forest], \n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_regressor=lr)\n",
    "clf.fit(X_train_train,y_tain_train)\n",
    "clf.score(X_train_train,y_tain_train)\n",
    "clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9037624654961689\n",
      "0.8093023073464667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "X_train_train,X_val,y_train_train,y_val = train_test_split(X_train,y_train,random_state=0)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_train,y_train_train)\n",
    "print(lr.score(X_train_train,y_train_train))\n",
    "print(lr.score(X_val,y_val))\n",
    "# params={'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]}\n",
    "# rdg_reg = Ridge()\n",
    "# clf = GridSearchCV(rdg_reg,params,cv=2,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "# clf.fit(X_train,y_train)\n",
    "\n",
    "# print(clf.best_params_)\n",
    "# #{'alpha': 4}\n",
    "\n",
    "# pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8702121149064014\n",
      "{'alpha': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>0.889264</td>\n",
       "      <td>0.870083</td>\n",
       "      <td>0.841777</td>\n",
       "      <td>0.867059</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882546</td>\n",
       "      <td>0.893587</td>\n",
       "      <td>0.897254</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>0.006251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.891099</td>\n",
       "      <td>0.872861</td>\n",
       "      <td>0.843596</td>\n",
       "      <td>0.869203</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>9</td>\n",
       "      <td>0.883661</td>\n",
       "      <td>0.895519</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.892232</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'alpha': 0.03}</td>\n",
       "      <td>0.891105</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>0.843597</td>\n",
       "      <td>0.869206</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>8</td>\n",
       "      <td>0.883661</td>\n",
       "      <td>0.895519</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.892232</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.891123</td>\n",
       "      <td>0.872877</td>\n",
       "      <td>0.843601</td>\n",
       "      <td>0.869218</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>7</td>\n",
       "      <td>0.883661</td>\n",
       "      <td>0.895519</td>\n",
       "      <td>0.897515</td>\n",
       "      <td>0.892232</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>0.891170</td>\n",
       "      <td>0.872912</td>\n",
       "      <td>0.843611</td>\n",
       "      <td>0.869249</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>6</td>\n",
       "      <td>0.883661</td>\n",
       "      <td>0.895518</td>\n",
       "      <td>0.897514</td>\n",
       "      <td>0.892231</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.891306</td>\n",
       "      <td>0.873018</td>\n",
       "      <td>0.843636</td>\n",
       "      <td>0.869338</td>\n",
       "      <td>0.019631</td>\n",
       "      <td>5</td>\n",
       "      <td>0.883660</td>\n",
       "      <td>0.895507</td>\n",
       "      <td>0.897504</td>\n",
       "      <td>0.892224</td>\n",
       "      <td>0.006110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>0.891562</td>\n",
       "      <td>0.873247</td>\n",
       "      <td>0.843665</td>\n",
       "      <td>0.869509</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>4</td>\n",
       "      <td>0.883654</td>\n",
       "      <td>0.895459</td>\n",
       "      <td>0.897458</td>\n",
       "      <td>0.892190</td>\n",
       "      <td>0.006091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.892066</td>\n",
       "      <td>0.873733</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>0.869833</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883612</td>\n",
       "      <td>0.895294</td>\n",
       "      <td>0.897319</td>\n",
       "      <td>0.892075</td>\n",
       "      <td>0.006041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>30</td>\n",
       "      <td>{'alpha': 30}</td>\n",
       "      <td>0.892887</td>\n",
       "      <td>0.874333</td>\n",
       "      <td>0.843361</td>\n",
       "      <td>0.870212</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883350</td>\n",
       "      <td>0.894855</td>\n",
       "      <td>0.897015</td>\n",
       "      <td>0.891740</td>\n",
       "      <td>0.005998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.893970</td>\n",
       "      <td>0.873828</td>\n",
       "      <td>0.841287</td>\n",
       "      <td>0.869714</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>3</td>\n",
       "      <td>0.881522</td>\n",
       "      <td>0.892796</td>\n",
       "      <td>0.895559</td>\n",
       "      <td>0.889959</td>\n",
       "      <td>0.006072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.003283      0.000772         0.000829        0.000058           0   \n",
       "1       0.002228      0.000087         0.000802        0.000118        0.01   \n",
       "2       0.002469      0.000784         0.000975        0.000184        0.03   \n",
       "3       0.003112      0.000928         0.001464        0.000320         0.1   \n",
       "4       0.001624      0.000017         0.000725        0.000173         0.3   \n",
       "5       0.001845      0.000342         0.000845        0.000330           1   \n",
       "6       0.001498      0.000085         0.000566        0.000009           3   \n",
       "7       0.001530      0.000009         0.000608        0.000058          10   \n",
       "8       0.001417      0.000026         0.000561        0.000002          30   \n",
       "9       0.001677      0.000152         0.000581        0.000011         100   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0     {'alpha': 0}           0.889264           0.870083           0.841777   \n",
       "1  {'alpha': 0.01}           0.891099           0.872861           0.843596   \n",
       "2  {'alpha': 0.03}           0.891105           0.872865           0.843597   \n",
       "3   {'alpha': 0.1}           0.891123           0.872877           0.843601   \n",
       "4   {'alpha': 0.3}           0.891170           0.872912           0.843611   \n",
       "5     {'alpha': 1}           0.891306           0.873018           0.843636   \n",
       "6     {'alpha': 3}           0.891562           0.873247           0.843665   \n",
       "7    {'alpha': 10}           0.892066           0.873733           0.843648   \n",
       "8    {'alpha': 30}           0.892887           0.874333           0.843361   \n",
       "9   {'alpha': 100}           0.893970           0.873828           0.841287   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.867059        0.019501               10            0.882546   \n",
       "1         0.869203        0.019562                9            0.883661   \n",
       "2         0.869206        0.019564                8            0.883661   \n",
       "3         0.869218        0.019569                7            0.883661   \n",
       "4         0.869249        0.019585                6            0.883661   \n",
       "5         0.869338        0.019631                5            0.883660   \n",
       "6         0.869509        0.019729                4            0.883654   \n",
       "7         0.869833        0.019955                2            0.883612   \n",
       "8         0.870212        0.020424                1            0.883350   \n",
       "9         0.869714        0.021700                3            0.881522   \n",
       "\n",
       "   split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.893587            0.897254          0.891129         0.006251  \n",
       "1            0.895519            0.897516          0.892232         0.006115  \n",
       "2            0.895519            0.897516          0.892232         0.006115  \n",
       "3            0.895519            0.897515          0.892232         0.006115  \n",
       "4            0.895518            0.897514          0.892231         0.006114  \n",
       "5            0.895507            0.897504          0.892224         0.006110  \n",
       "6            0.895459            0.897458          0.892190         0.006091  \n",
       "7            0.895294            0.897319          0.892075         0.006041  \n",
       "8            0.894855            0.897015          0.891740         0.005998  \n",
       "9            0.892796            0.895559          0.889959         0.006072  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "param_grid = {\"alpha\":[0,.01,0.03,0.1,0.3,1,3,10,30,100]}\n",
    "\n",
    "\n",
    "# \"min_child_weigh\":[1,2,4,7,10]\n",
    "# \"colsample_bytree\":[0.5,0.6,0.7,0.8,0.9,1]\n",
    "# \"max_depth\":[3,4,5],\"learning_rate\":[0.03,0.1,0.3]\n",
    "# \"colsample_bytree\":[0.5,0.6,0.7,0.8,0.9,1]\n",
    "\n",
    "ridge = Ridge()\n",
    "grid_search = GridSearchCV(ridge, param_grid)\n",
    "# , scoring = \"neg_mean_squared_error\"\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
